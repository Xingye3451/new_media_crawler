#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä»»åŠ¡ç®¡ç†æœåŠ¡
æä¾›ä»»åŠ¡CRUDã€è§†é¢‘ç®¡ç†ã€æ—¥å¿—è®°å½•ç­‰åŠŸèƒ½
"""

import uuid
import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta

from models.task_models import (
    TaskStatus, TaskType, ActionType
)
from var import media_crawler_db_var
from tools.time_util import get_current_datetime_utc8

logger = logging.getLogger(__name__)

async def _get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        # ç›´æ¥åˆ›å»ºæ•°æ®åº“è¿æ¥ï¼Œä¸ä¾èµ–ContextVar
        from config.env_config_loader import config_loader
        from async_db import AsyncMysqlDB
        import aiomysql
        
        db_config = config_loader.get_database_config()
        
        pool = await aiomysql.create_pool(
            host=db_config['host'],
            port=db_config['port'],
            user=db_config['username'],
            password=db_config['password'],
            db=db_config['database'],
            autocommit=True,
            charset='utf8mb4',
            # è®¾ç½®æ—¶åŒºä¸ºUTC+8
            init_command="SET time_zone = '+08:00'"
        )
        
        async_db_obj = AsyncMysqlDB(pool)
        return async_db_obj
        
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise


class TaskManagementService:
    """ä»»åŠ¡ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.db = None
    
    async def _get_db(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not self.db:
            self.db = await _get_db_connection()
        return self.db
    
    async def create_task(self, task_data: Dict[str, Any]) -> str:
        """åˆ›å»ºä»»åŠ¡"""
        db = await self._get_db()
        try:
            task_id = str(uuid.uuid4())
            
            # æ„å»ºæ’å…¥SQL
            insert_sql = """
            INSERT INTO crawler_tasks (
                id, platform, task_type, keywords, user_id, params, priority,
                ip_address, user_security_id, user_signature, created_at, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            import json
            params_json = json.dumps(task_data.get('params', {})) if task_data.get('params') else None
            
            await db.execute(insert_sql, 
                task_id,
                task_data['platform'],
                task_data['task_type'],
                task_data['keywords'],
                task_data.get('user_id'),
                params_json,
                task_data.get('priority', 0),
                task_data.get('ip_address'),
                task_data.get('user_security_id'),
                task_data.get('user_signature'),
                get_current_datetime_utc8(),
                get_current_datetime_utc8()
            )
            
            # è®°å½•æ—¥å¿—
            await self._add_task_log(
                task_id=task_id,
                action_type=ActionType.CREATE,
                content=f"åˆ›å»ºä»»åŠ¡: {task_data['platform']} - {task_data['keywords']}",
                operator=task_data.get('user_id', 'system')
            )
            
            logger.info(f"ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")
            return task_id
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")
            raise
    
    async def get_task(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡è¯¦æƒ…"""
        db = await self._get_db()
        try:
            query = """
            SELECT * FROM crawler_tasks 
            WHERE id = %s AND deleted = 0
            """
            
            result = await db.get_first(query, task_id)
            
            if result:
                # è½¬æ¢æ—¶é—´å­—æ®µä¸ºUTC+8æ ¼å¼
                if result.get("created_at"):
                    if isinstance(result["created_at"], datetime):
                        result["created_at"] = result["created_at"].isoformat()
                if result.get("updated_at"):
                    if isinstance(result["updated_at"], datetime):
                        result["updated_at"] = result["updated_at"].isoformat()
                if result.get("started_at"):
                    if isinstance(result["started_at"], datetime):
                        result["started_at"] = result["started_at"].isoformat()
                if result.get("completed_at"):
                    if isinstance(result["completed_at"], datetime):
                        result["completed_at"] = result["completed_at"].isoformat()
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥ {task_id}: {str(e)}")
            raise
    
    async def update_task(self, task_id: str, update_data: Dict[str, Any]) -> bool:
        """æ›´æ–°ä»»åŠ¡"""
        db = await self._get_db()
        try:
            # æ„å»ºæ›´æ–°SQL
            set_clauses = []
            params = []
            
            for key, value in update_data.items():
                if key in ['status', 'progress', 'result_count', 'error_message', 
                          'is_favorite', 'is_pinned', 'updated_at']:
                    set_clauses.append(f"{key} = %s")
                    params.append(value)
            
            if not set_clauses:
                return False
            
            set_clauses.append("updated_at = %s")
            params.append(get_current_datetime_utc8())
            params.append(task_id)
            
            update_sql = f"""
            UPDATE crawler_tasks 
            SET {', '.join(set_clauses)}
            WHERE id = %s AND deleted = 0
            """
            
            result = await db.execute(update_sql, *params)
            
            if result:
                # è®°å½•æ—¥å¿—
                await self._add_task_log(
                    task_id=task_id,
                    action_type=ActionType.UPDATE,
                    content=f"æ›´æ–°ä»»åŠ¡: {update_data}",
                    operator=update_data.get('operator', 'system')
                )
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥ {task_id}: {str(e)}")
            raise
    
    async def delete_task(self, task_id: str, operator: str = 'system') -> bool:
        """åˆ é™¤ä»»åŠ¡ï¼ˆè½¯åˆ é™¤ï¼‰"""
        db = await self._get_db()
        try:
            update_sql = """
            UPDATE crawler_tasks 
            SET deleted = 1, updated_at = %s
            WHERE id = %s AND deleted = 0
            """
            
            result = await db.execute(update_sql, get_current_datetime_utc8(), task_id)
            
            if result:
                # è®°å½•æ—¥å¿—
                await self._add_task_log(
                    task_id=task_id,
                    action_type=ActionType.DELETE,
                    content="åˆ é™¤ä»»åŠ¡",
                    operator=operator
                )
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥ {task_id}: {str(e)}")
            raise
    
    async def list_tasks(self, filters: Dict[str, Any], page: int = 1, page_size: int = 20) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡åˆ—è¡¨"""
        db = await self._get_db()
        try:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clauses = ["deleted = 0"]
            params = []
            
            if filters.get('platform'):
                where_clauses.append("platform = %s")
                params.append(filters['platform'])
            
            if filters.get('status'):
                where_clauses.append("status = %s")
                params.append(filters['status'])
            
            if filters.get('task_type'):
                where_clauses.append("task_type = %s")
                params.append(filters['task_type'])
            
            if filters.get('keyword'):
                where_clauses.append("keywords LIKE %s")
                params.append(f"%{filters['keyword']}%")
            
            if filters.get('is_favorite') is not None:
                where_clauses.append("is_favorite = %s")
                params.append(filters['is_favorite'])
            
            if filters.get('is_pinned') is not None:
                where_clauses.append("is_pinned = %s")
                params.append(filters['is_pinned'])
            
            if filters.get('user_id'):
                where_clauses.append("user_id = %s")
                params.append(filters['user_id'])
            
            where_sql = " AND ".join(where_clauses)
            
            # æ„å»ºæ’åº
            sort_field = filters.get('sort_by', 'created_at')
            sort_order = filters.get('sort_order', 'desc')
            
            # éªŒè¯æ’åºå­—æ®µ
            valid_sort_fields = ['created_at', 'updated_at', 'priority', 'status', 'result_count']
            if sort_field not in valid_sort_fields:
                sort_field = 'created_at'
            
            order_sql = f"{sort_field} {sort_order.upper()}"
            
            # æŸ¥è¯¢æ€»æ•°
            count_sql = f"SELECT COUNT(*) as total FROM crawler_tasks WHERE {where_sql}"
            count_result = await db.get_first(count_sql, *params)
            total = count_result['total'] if count_result else 0
            
            # æŸ¥è¯¢æ•°æ®
            offset = (page - 1) * page_size
            query_sql = f"""
            SELECT * FROM crawler_tasks 
            WHERE {where_sql}
            ORDER BY {order_sql}
            LIMIT %s OFFSET %s
            """
            
            query_params = params + [page_size, offset]
            results = await db.query(query_sql, *query_params)
            
            # è½¬æ¢æ—¶é—´å­—æ®µä¸ºUTC+8æ ¼å¼
            for item in results:
                if item.get("created_at"):
                    if isinstance(item["created_at"], datetime):
                        item["created_at"] = item["created_at"].isoformat()
                if item.get("updated_at"):
                    if isinstance(item["updated_at"], datetime):
                        item["updated_at"] = item["updated_at"].isoformat()
                if item.get("started_at"):
                    if isinstance(item["started_at"], datetime):
                        item["started_at"] = item["started_at"].isoformat()
                if item.get("completed_at"):
                    if isinstance(item["completed_at"], datetime):
                        item["completed_at"] = item["completed_at"].isoformat()
                
                # ğŸ†• ä¸ºå·²å®Œæˆçš„ä»»åŠ¡åŠ¨æ€æŸ¥è¯¢å…³è”çš„è§†é¢‘æ•°é‡
                if item.get("status") in ["completed", "success"]:
                    try:
                        # æŸ¥è¯¢è¯¥ä»»åŠ¡å…³è”çš„è§†é¢‘æ•°é‡
                        video_count_sql = "SELECT COUNT(*) as video_count FROM unified_content WHERE task_id = %s"
                        video_count_result = await db.get_first(video_count_sql, item["id"])
                        actual_video_count = video_count_result['video_count'] if video_count_result else 0
                        
                        # æ›´æ–°ä»»åŠ¡çš„è§†é¢‘æ•°é‡
                        item["actual_video_count"] = actual_video_count
                        item["statistics"] = {
                            "total_videos": actual_video_count
                        }
                        
                        # å¦‚æœæ•°æ®åº“ä¸­çš„result_countä¸º0ä½†å®é™…æœ‰è§†é¢‘ï¼Œæ›´æ–°result_count
                        if item.get("result_count", 0) == 0 and actual_video_count > 0:
                            item["result_count"] = actual_video_count
                            
                    except Exception as e:
                        logger.warning(f"æŸ¥è¯¢ä»»åŠ¡ {item['id']} çš„è§†é¢‘æ•°é‡å¤±è´¥: {e}")
                        item["actual_video_count"] = item.get("result_count", 0)
                        item["statistics"] = {
                            "total_videos": item.get("result_count", 0)
                        }
                else:
                    # æœªå®Œæˆçš„ä»»åŠ¡ä½¿ç”¨æ•°æ®åº“ä¸­çš„result_count
                    item["actual_video_count"] = item.get("result_count", 0)
                    item["statistics"] = {
                        "total_videos": item.get("result_count", 0)
                    }
            
            return {
                'total': total,
                'page': page,
                'page_size': page_size,
                'total_pages': (total + page_size - 1) // page_size,
                'items': results
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            raise
    
    async def get_task_videos(self, task_id: str, page: int = 1, page_size: int = 20) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡çš„è§†é¢‘åˆ—è¡¨"""
        db = await self._get_db()
        try:
            # æŸ¥è¯¢æ€»æ•°
            count_sql = "SELECT COUNT(*) as total FROM unified_content WHERE task_id = %s"
            count_result = await db.get_first(count_sql, task_id)
            total = count_result['total'] if count_result else 0
            
            # æŸ¥è¯¢æ•°æ®
            offset = (page - 1) * page_size
            query_sql = """
            SELECT * FROM unified_content 
            WHERE task_id = %s
            ORDER BY add_ts DESC
            LIMIT %s OFFSET %s
            """
            
            results = await db.query(query_sql, task_id, page_size, offset)
            
            return {
                'total': total,
                'page': page,
                'page_size': page_size,
                'total_pages': (total + page_size - 1) // page_size,
                'items': results
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è§†é¢‘åˆ—è¡¨å¤±è´¥ {task_id}: {str(e)}")
            raise
    
    async def get_video_detail(self, video_id: int) -> Optional[Dict]:
        """è·å–è§†é¢‘è¯¦æƒ…"""
        db = await self._get_db()
        try:
            query_sql = "SELECT * FROM unified_content WHERE id = %s"
            result = await db.get_first(query_sql, video_id)
            return result
            
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥ {video_id}: {str(e)}")
            raise
    
    async def update_video_collection(self, video_id: int, is_collected: bool, minio_url: str = None) -> bool:
        """æ›´æ–°è§†é¢‘æ”¶è—çŠ¶æ€"""
        db = await self._get_db()
        try:
            # æ›´æ–°minio_urlå­—æ®µ
            if minio_url:
                update_sql = "UPDATE unified_content SET minio_url = %s WHERE id = %s"
                params = [minio_url, video_id]
            else:
                # å¦‚æœæ²¡æœ‰minio_urlï¼Œæš‚æ—¶è¿”å›æˆåŠŸ
                return True
            
            result = await db.execute(update_sql, *params)
            return bool(result)
            
        except Exception as e:
            logger.error(f"æ›´æ–°è§†é¢‘æ”¶è—çŠ¶æ€å¤±è´¥ {video_id}: {str(e)}")
            raise
    
    async def get_task_statistics(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        db = await self._get_db()
        try:
            # ä»»åŠ¡ç»Ÿè®¡
            task_stats_sql = """
            SELECT 
                COUNT(*) as total_tasks,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_tasks,
                SUM(CASE WHEN status = 'running' THEN 1 ELSE 0 END) as running_tasks,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed_tasks
            FROM crawler_tasks 
            WHERE deleted = 0
            """
            
            task_stats = await db.get_first(task_stats_sql)
            
            # è§†é¢‘ç»Ÿè®¡ - ä½¿ç”¨ç»Ÿä¸€å†…å®¹è¡¨
            video_stats_sql = """
            SELECT 
                COUNT(*) as total_videos
            FROM unified_content
            """
            
            video_stats = await db.get_first(video_stats_sql)
            
            # å¹³å°ç»Ÿè®¡
            platform_stats_sql = """
            SELECT platform, COUNT(*) as count
            FROM unified_content
            GROUP BY platform
            """
            
            platform_stats = await db.query(platform_stats_sql)
            
            # è¿”å›æ‰å¹³åŒ–çš„æ•°æ®ç»“æ„ï¼Œä»¥ä¾¿å‰ç«¯JavaScriptèƒ½å¤Ÿæ­£ç¡®è¯»å–
            return {
                'total_tasks': task_stats.get('total_tasks', 0) if task_stats else 0,
                'completed_tasks': task_stats.get('completed_tasks', 0) if task_stats else 0,
                'running_tasks': task_stats.get('running_tasks', 0) if task_stats else 0,
                'failed_tasks': task_stats.get('failed_tasks', 0) if task_stats else 0,
                'total_videos': video_stats.get('total_videos', 0) if video_stats else 0,
                'platform_stats': {row['platform']: row['count'] for row in platform_stats} if platform_stats else {},
                # ä¿ç•™åŸå§‹åµŒå¥—ç»“æ„ä»¥ä¾¿å…¶ä»–APIä½¿ç”¨
                'task_stats': task_stats,
                'video_stats': video_stats,
                'platform_stats_list': platform_stats
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}")
            raise
    
    async def get_task_logs(self, task_id: str, page: int = 1, page_size: int = 50) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡æ—¥å¿—"""
        db = await self._get_db()
        try:
            # æŸ¥è¯¢æ€»æ•°
            count_sql = "SELECT COUNT(*) as total FROM crawler_task_logs WHERE task_id = %s"
            count_result = await db.get_first(count_sql, task_id)
            total = count_result['total'] if count_result else 0
            
            # æŸ¥è¯¢æ•°æ®
            offset = (page - 1) * page_size
            query_sql = """
            SELECT id, task_id, platform, account_id, log_level, message, step, progress, extra_data, created_at
            FROM crawler_task_logs 
            WHERE task_id = %s
            ORDER BY created_at DESC
            LIMIT %s OFFSET %s
            """
            
            results = await db.query(query_sql, task_id, page_size, offset)
            
            # è½¬æ¢æ•°æ®æ ¼å¼ä»¥ä¿æŒAPIå…¼å®¹æ€§
            formatted_results = []
            for row in results:
                # å°è¯•ä»extra_dataä¸­æå–operatorä¿¡æ¯
                operator = 'system'
                try:
                    if row.get('extra_data'):
                        import json
                        extra_data = json.loads(row['extra_data'])
                        operator = extra_data.get('operator', 'system')
                except:
                    pass
                
                # æ„å»ºå…¼å®¹çš„å“åº”æ ¼å¼
                formatted_row = {
                    'id': row['id'],
                    'task_id': row['task_id'],
                    'action_type': row.get('step', 'unknown'),  # ä½¿ç”¨stepå­—æ®µä½œä¸ºaction_type
                    'content': row.get('message', ''),  # ä½¿ç”¨messageå­—æ®µä½œä¸ºcontent
                    'operator': operator,
                    'created_at': row['created_at'].isoformat() if row['created_at'] else None,
                    # æ·»åŠ åŸå§‹å­—æ®µä»¥ä¾¿è°ƒè¯•
                    'platform': row.get('platform'),
                    'log_level': row.get('log_level'),
                    'step': row.get('step'),
                    'progress': row.get('progress'),
                    'extra_data': row.get('extra_data')
                }
                formatted_results.append(formatted_row)
            
            return {
                'total': total,
                'page': page,
                'page_size': page_size,
                'total_pages': (total + page_size - 1) // page_size,
                'items': formatted_results
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡æ—¥å¿—å¤±è´¥ {task_id}: {str(e)}")
            raise
    
    async def _add_task_log(self, task_id: str, action_type: str, content: str, operator: str = 'system'):
        """æ·»åŠ ä»»åŠ¡æ—¥å¿—"""
        db = await self._get_db()
        try:
            # ä½¿ç”¨å®é™…çš„æ•°æ®åº“è¡¨ç»“æ„å­—æ®µ
            insert_sql = """
            INSERT INTO crawler_task_logs (task_id, platform, account_id, log_level, message, step, progress, extra_data, created_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            # å°†action_typeæ˜ å°„åˆ°stepå­—æ®µï¼Œcontentæ˜ å°„åˆ°messageå­—æ®µï¼Œoperatorå­˜å‚¨åˆ°extra_data
            await db.execute(insert_sql, 
                task_id, 
                'system',  # platform
                None,      # account_id
                'INFO',    # log_level
                content,   # message (ç›´æ¥ä½¿ç”¨content)
                action_type,  # step (ä½¿ç”¨action_typeä½œä¸ºstep)
                0,         # progress
                f'{{"operator": "{operator}"}}',  # extra_data (JSONæ ¼å¼)
                datetime.now()
            )
            
        except Exception as e:
            logger.error(f"æ·»åŠ ä»»åŠ¡æ—¥å¿—å¤±è´¥: {str(e)}")
    
    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.db = None 