# å£°æ˜ï¼šæœ¬ä»£ç ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ç›®çš„ä½¿ç”¨ã€‚ä½¿ç”¨è€…åº”éµå®ˆä»¥ä¸‹åŸåˆ™ï¼š  
# 1. ä¸å¾—ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚  
# 2. ä½¿ç”¨æ—¶åº”éµå®ˆç›®æ ‡å¹³å°çš„ä½¿ç”¨æ¡æ¬¾å’Œrobots.txtè§„åˆ™ã€‚  
# 3. ä¸å¾—è¿›è¡Œå¤§è§„æ¨¡çˆ¬å–æˆ–å¯¹å¹³å°é€ æˆè¿è¥å¹²æ‰°ã€‚  
# 4. åº”åˆç†æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…ç»™ç›®æ ‡å¹³å°å¸¦æ¥ä¸å¿…è¦çš„è´Ÿæ‹…ã€‚   
# 5. ä¸å¾—ç”¨äºä»»ä½•éæ³•æˆ–ä¸å½“çš„ç”¨é€”ã€‚
#   
# è¯¦ç»†è®¸å¯æ¡æ¬¾è¯·å‚é˜…é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„LICENSEæ–‡ä»¶ã€‚  
# ä½¿ç”¨æœ¬ä»£ç å³è¡¨ç¤ºæ‚¨åŒæ„éµå®ˆä¸Šè¿°åŸåˆ™å’ŒLICENSEä¸­çš„æ‰€æœ‰æ¡æ¬¾ã€‚  


# -*- coding: utf-8 -*-
# @Author  : relakkes@gmail.com
# @Time    : 2024/1/14 18:46
# @Desc    : å¿«æ‰‹å­˜å‚¨å®ç°ç±» - ä½¿ç”¨ç»Ÿä¸€å­˜å‚¨ç³»ç»Ÿ

import asyncio
import csv
import json
import os
import pathlib
from typing import Dict, List, Tuple

import aiofiles

import config
from base.base_crawler import AbstractStore
from tools import utils, words
from var import crawler_type_var, source_keyword_var
from store.unified_store_impl import UnifiedStoreImplement


def calculate_number_of_files(file_store_path: str) -> int:
    """è®¡ç®—æ•°æ®ä¿å­˜æ–‡ä»¶çš„å‰éƒ¨åˆ†æ’åºæ•°å­—ï¼Œæ”¯æŒæ¯æ¬¡è¿è¡Œä»£ç ä¸å†™åˆ°åŒä¸€ä¸ªæ–‡ä»¶ä¸­
    Args:
        file_store_path;
    Returns:
        file nums
    """
    if not os.path.exists(file_store_path):
        return 1
    try:
        return max([int(file_name.split("_")[0]) for file_name in os.listdir(file_store_path)]) + 1
    except ValueError:
        return 1


class KuaishouCsvStoreImplement(AbstractStore):
    csv_store_path: str = "data/kuaishou"
    file_count: int = calculate_number_of_files(csv_store_path)

    def make_save_file_name(self, store_type: str) -> str:
        """
        make save file name by store type
        Args:
            store_type: contents or comments

        Returns: eg: data/kuaishou/search_comments_20240114.csv ...

        """
        return f"{self.csv_store_path}/{self.file_count}_{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}.csv"

    async def save_data_to_csv(self, save_item: Dict, store_type: str):
        """
        Below is a simple way to save it in CSV format.
        Args:
            save_item:  save content dict info
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns: no returns

        """
        pathlib.Path(self.csv_store_path).mkdir(parents=True, exist_ok=True)
        save_file_name = self.make_save_file_name(store_type=store_type)
        async with aiofiles.open(save_file_name, mode='a+', encoding="utf-8-sig", newline="") as f:
            writer = csv.writer(f)
            if await f.tell() == 0:
                await writer.writerow(save_item.keys())
            await writer.writerow(save_item.values())

    async def store_content(self, content_item: Dict):
        """
        Kuaishou content CSV storage implementation
        Args:
            content_item: video item dict

        Returns:

        """
        await self.save_data_to_csv(save_item=content_item, store_type="contents")

    async def store_comment(self, comment_item: Dict):
        """
        Kuaishou comment CSV storage implementation
        Args:
            comment_item: comment item dict

        Returns:

        """
        await self.save_data_to_csv(save_item=comment_item, store_type="comments")


class KuaishouDbStoreImplement(AbstractStore):
    """å¿«æ‰‹æ•°æ®åº“å­˜å‚¨å®ç° - ä½¿ç”¨ç»Ÿä¸€å­˜å‚¨ç³»ç»Ÿ"""
    
    def __init__(self):
        self.unified_store = UnifiedStoreImplement("kuaishou")
    
    def set_redis_callback(self, callback):
        """è®¾ç½®Rediså›è°ƒå‡½æ•°"""
        self.unified_store.set_redis_callback(callback)
    
    async def store_content(self, content_item: Dict):
        """
        å¿«æ‰‹å†…å®¹æ•°æ®åº“å­˜å‚¨å®ç°
        Args:
            content_item: å†…å®¹å­—å…¸

        Returns:

        """
        await self.unified_store.store_content(content_item)

    async def store_comment(self, comment_item: Dict):
        """
        å¿«æ‰‹è¯„è®ºæ•°æ®åº“å­˜å‚¨å®ç°
        Args:
            comment_item: è¯„è®ºå­—å…¸

        Returns:

        """
        await self.unified_store.store_comment(comment_item)

    async def store_creator(self, creator_item: Dict):
        """
        å¿«æ‰‹åˆ›ä½œè€…æ•°æ®åº“å­˜å‚¨å®ç°
        Args:
            creator_item: åˆ›ä½œè€…å­—å…¸

        Returns:

        """
        await self.unified_store.store_creator(creator_item)

    async def get_all_content(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å­˜å‚¨çš„å†…å®¹
        Returns:
            List[Dict]: å†…å®¹åˆ—è¡¨
        """
        return await self.unified_store.get_all_content()

    async def update_kuaishou_video(self, video_item: Dict, task_id: str = None):
        """
        å¿«æ‰‹è§†é¢‘å†…å®¹æ›´æ–°ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        Args:
            video_item: è§†é¢‘è¯¦æƒ…å­—å…¸
            task_id: ä»»åŠ¡IDï¼Œå¯é€‰
        """
        photo_info: Dict = video_item.get("photo", {})
        video_id = photo_info.get("id")
        if not video_id:
            return
        user_info = video_item.get("author", {})
        save_content_item = {
            "video_id": video_id,
            "video_type": str(video_item.get("type")),
            "title": photo_info.get("caption", "")[:500],
            "desc": photo_info.get("caption", ""),
            "user_id": user_info.get("id"),
            "nickname": user_info.get("name"),
            "avatar": user_info.get("headerUrl"),
            "liked_count": photo_info.get("likeCount", 0),
            "comment_count": photo_info.get("commentCount", 0),
            "share_count": photo_info.get("shareCount", 0),
            "collect_count": photo_info.get("collectCount", 0),
            "viewd_count": photo_info.get("viewCount", 0),
            "video_cover_url": photo_info.get("coverUrl"),  # å°é¢å›¾ç‰‡
            "video_url": photo_info.get("photoUrl"),  # è§†é¢‘æ’­æ”¾é“¾æ¥
            "video_play_url": photo_info.get("photoUrl"),  # è§†é¢‘æ’­æ”¾é“¾æ¥
            "video_download_url": photo_info.get("photoUrl"),  # è§†é¢‘ä¸‹è½½é“¾æ¥ï¼ˆåˆå§‹å€¼ï¼‰
            "create_time": photo_info.get("timestamp"),
            "last_modify_ts": photo_info.get("timestamp"),
            "raw_data": json.dumps(video_item, ensure_ascii=False),
            # ğŸ†• æ–°å¢å­—æ®µ
            "author_signature": user_info.get("signature"),
            "author_unique_id": user_info.get("id"),
            "author_sec_uid": user_info.get("secUid"),
            "author_short_id": user_info.get("shortId"),
            "video_share_url": photo_info.get("shareUrl"),
            "image_urls": json.dumps(photo_info.get("coverUrls", []), ensure_ascii=False),
            "audio_url": photo_info.get("audioUrl"),
            "file_urls": json.dumps(photo_info.get("fileUrls", []), ensure_ascii=False),
            "ip_location": photo_info.get("ipLocation"),
            "location": photo_info.get("location"),
            "tags": json.dumps(photo_info.get("tags", []), ensure_ascii=False),
            "categories": json.dumps(photo_info.get("categories", []), ensure_ascii=False),
            "topics": json.dumps(photo_info.get("topics", []), ensure_ascii=False),
            "is_favorite": 1 if photo_info.get("isFavorite") else 0,
            "is_deleted": 1 if photo_info.get("isDeleted") else 0,
            "is_private": 1 if photo_info.get("isPrivate") else 0,
            "is_original": 1 if photo_info.get("isOriginal") else 0,
            "minio_url": photo_info.get("minioUrl"),
            "local_path": photo_info.get("localPath"),
            # æ·»åŠ å¿…éœ€å­—æ®µ
            "source_keyword": source_keyword_var.get(),
            "platform": "kuaishou",
            "task_id": task_id,
        }
        
        # ğŸ†• ä¼˜å…ˆä½¿ç”¨é«˜æ¸…è§†é¢‘ä¸‹è½½é“¾æ¥
        if "manifest" in photo_info:
            manifest = photo_info.get("manifest", {})
            if "adaptationSet" in manifest and manifest["adaptationSet"]:
                adaptation_set = manifest["adaptationSet"][0]
                if "representation" in adaptation_set and adaptation_set["representation"]:
                    representation = adaptation_set["representation"][0]
                    hd_video_url = representation.get("url")
                    if hd_video_url:
                        save_content_item["video_download_url"] = hd_video_url
                        utils.logger.info(f"[KuaishouStore] ä½¿ç”¨é«˜æ¸…è§†é¢‘ä¸‹è½½é“¾æ¥: {hd_video_url[:100]}...")
        
        # å¤‡ç”¨ï¼šä½¿ç”¨videoResourceä¸­çš„H264é“¾æ¥
        if "videoResource" in photo_info:
            video_resource = photo_info.get("videoResource", {})
            if "h264" in video_resource:
                h264 = video_resource.get("h264", {})
                if "adaptationSet" in h264 and h264["adaptationSet"]:
                    adaptation_set = h264["adaptationSet"][0]
                    if "representation" in adaptation_set and adaptation_set["representation"]:
                        representation = adaptation_set["representation"][0]
                        h264_video_url = representation.get("url")
                        if h264_video_url and save_content_item["video_download_url"] == photo_info.get("photoUrl"):
                            save_content_item["video_download_url"] = h264_video_url
                            utils.logger.info(f"[KuaishouStore] ä½¿ç”¨H264è§†é¢‘ä¸‹è½½é“¾æ¥: {h264_video_url[:100]}...")
        
        utils.logger.info(f"[KuaishouStore] æœ€ç»ˆè§†é¢‘ä¸‹è½½é“¾æ¥: {save_content_item['video_download_url'][:100]}...")
        
        await self.unified_store.store_content(save_content_item)


class KuaishouJsonStoreImplement(AbstractStore):
    json_store_path: str = "data/kuaishou/json"
    words_store_path: str = "data/kuaishou/words"

    lock = asyncio.Lock()
    file_count: int = calculate_number_of_files(json_store_path)
    WordCloud = words.AsyncWordCloudGenerator()

    def make_save_file_name(self, store_type: str) -> Tuple[str, str]:
        """
        make save file name by store type
        Args:
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns:

        """

        return (
            f"{self.json_store_path}/{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}.json",
            f"{self.words_store_path}/{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}"
        )
    async def save_data_to_json(self, save_item: Dict, store_type: str):
        """
        Below is a simple way to save it in json format.
        Args:
            save_item: save content dict info
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns:

        """
        pathlib.Path(self.json_store_path).mkdir(parents=True, exist_ok=True)
        pathlib.Path(self.words_store_path).mkdir(parents=True, exist_ok=True)
        save_file_name,words_file_name_prefix = self.make_save_file_name(store_type=store_type)
        save_data = []

        async with self.lock:
            if os.path.exists(save_file_name):
                async with aiofiles.open(save_file_name, 'r', encoding='utf-8') as file:
                    save_data = json.loads(await file.read())

            save_data.append(save_item)
            async with aiofiles.open(save_file_name, 'w', encoding='utf-8') as file:
                await file.write(json.dumps(save_data, ensure_ascii=False))

            if config.ENABLE_GET_COMMENTS and config.ENABLE_GET_WORDCLOUD:
                try:
                    await self.WordCloud.generate_word_frequency_and_cloud(save_data, words_file_name_prefix)
                except:
                    pass

    async def store_content(self, content_item: Dict):
        """
        content JSON storage implementation
        Args:
            content_item:

        Returns:

        """
        await self.save_data_to_json(content_item, "contents")

    async def store_comment(self, comment_item: Dict):
        """
        comment JSON storage implementation
        Args:
            comment_item:

        Returns:

        """
        await self.save_data_to_json(comment_item, "comments")


    async def store_creator(self, creator_item: Dict):
        """
        Kuaishou creator JSON storage implementation
        Args:
            creator_item: creator item dict

        Returns:

        """
        await self.save_data_to_json(save_item=creator_item, store_type="creator")


class KuaishouRedisStoreImplement(AbstractStore):
    """å¿«æ‰‹Rediså­˜å‚¨å®ç° - ä½¿ç”¨ç»Ÿä¸€å­˜å‚¨ç³»ç»Ÿ"""
    
    def __init__(self, redis_callback=None):
        self.unified_store = UnifiedStoreImplement("kuaishou", redis_callback)
    
    def set_redis_callback(self, callback):
        """è®¾ç½®Rediså›è°ƒå‡½æ•°"""
        self.unified_store.set_redis_callback(callback)
    
    async def store_content(self, content_item: Dict):
        """
        å¿«æ‰‹å†…å®¹Rediså­˜å‚¨å®ç°
        Args:
            content_item: å†…å®¹å­—å…¸
        """
        await self.unified_store.store_content(content_item)

    async def store_comment(self, comment_item: Dict):
        """
        å¿«æ‰‹è¯„è®ºRediså­˜å‚¨å®ç°
        Args:
            comment_item: è¯„è®ºå­—å…¸
        """
        await self.unified_store.store_comment(comment_item)

    async def store_creator(self, creator_item: Dict):
        """
        å¿«æ‰‹åˆ›ä½œè€…Rediså­˜å‚¨å®ç°
        Args:
            creator_item: åˆ›ä½œè€…å­—å…¸
        """
        await self.unified_store.store_creator(creator_item)

    async def get_all_content(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å­˜å‚¨çš„å†…å®¹
        Returns:
            List[Dict]: å†…å®¹åˆ—è¡¨
        """
        return await self.unified_store.get_all_content()
        await self.save_data_to_json(creator, "creator")