# å£°æ˜ï¼šæœ¬ä»£ç ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ç›®çš„ä½¿ç”¨ã€‚ä½¿ç”¨è€…åº”éµå®ˆä»¥ä¸‹åŸåˆ™ï¼š  
# 1. ä¸å¾—ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚  
# 2. ä½¿ç”¨æ—¶åº”éµå®ˆç›®æ ‡å¹³å°çš„ä½¿ç”¨æ¡æ¬¾å’Œrobots.txtè§„åˆ™ã€‚  
# 3. ä¸å¾—è¿›è¡Œå¤§è§„æ¨¡çˆ¬å–æˆ–å¯¹å¹³å°é€ æˆè¿è¥å¹²æ‰°ã€‚  
# 4. åº”åˆç†æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…ç»™ç›®æ ‡å¹³å°å¸¦æ¥ä¸å¿…è¦çš„è´Ÿæ‹…ã€‚   
# 5. ä¸å¾—ç”¨äºä»»ä½•éæ³•æˆ–ä¸å½“çš„ç”¨é€”ã€‚
#   
# è¯¦ç»†è®¸å¯æ¡æ¬¾è¯·å‚é˜…é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„LICENSEæ–‡ä»¶ã€‚  
# ä½¿ç”¨æœ¬ä»£ç å³è¡¨ç¤ºæ‚¨åŒæ„éµå®ˆä¸Šè¿°åŸåˆ™å’ŒLICENSEä¸­çš„æ‰€æœ‰æ¡æ¬¾ã€‚  


# -*- coding: utf-8 -*-
# @Author  : relakkes@gmail.com
# @Time    : 2024/1/14 18:46
# @Desc    : æŠ–éŸ³å­˜å‚¨å®ç°ç±»
import asyncio
import csv
import json
import os
import pathlib
from typing import Dict, List

import aiofiles

import config
from base.base_crawler import AbstractStore
from tools import utils, words
from var import crawler_type_var


def calculate_number_of_files(file_store_path: str) -> int:
    """è®¡ç®—æ•°æ®ä¿å­˜æ–‡ä»¶çš„å‰éƒ¨åˆ†æ’åºæ•°å­—ï¼Œæ”¯æŒæ¯æ¬¡è¿è¡Œä»£ç ä¸å†™åˆ°åŒä¸€ä¸ªæ–‡ä»¶ä¸­
    Args:
        file_store_path;
    Returns:
        file nums
    """
    if not os.path.exists(file_store_path):
        return 1
    try:
        return max([int(file_name.split("_")[0]) for file_name in os.listdir(file_store_path)]) + 1
    except ValueError:
        return 1


class DouyinCsvStoreImplement(AbstractStore):
    csv_store_path: str = "data/douyin"
    file_count: int = calculate_number_of_files(csv_store_path)

    def make_save_file_name(self, store_type: str) -> str:
        """
        make save file name by store type
        Args:
            store_type: contents or comments

        Returns: eg: data/douyin/search_comments_20240114.csv ...

        """
        return f"{self.csv_store_path}/{self.file_count}_{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}.csv"

    async def save_data_to_csv(self, save_item: Dict, store_type: str):
        """
        Below is a simple way to save it in CSV format.
        Args:
            save_item:  save content dict info
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns: no returns

        """
        pathlib.Path(self.csv_store_path).mkdir(parents=True, exist_ok=True)
        save_file_name = self.make_save_file_name(store_type=store_type)
        async with aiofiles.open(save_file_name, mode='a+', encoding="utf-8-sig", newline="") as f:
            writer = csv.writer(f)
            if await f.tell() == 0:
                await writer.writerow(save_item.keys())
            await writer.writerow(save_item.values())

    async def store_content(self, content_item: Dict):
        """
        Douyin content CSV storage implementation
        Args:
            content_item: note item dict

        Returns:

        """
        await self.save_data_to_csv(save_item=content_item, store_type="contents")

    async def store_comment(self, comment_item: Dict):
        """
        Douyin comment CSV storage implementation
        Args:
            comment_item: comment item dict

        Returns:

        """
        await self.save_data_to_csv(save_item=comment_item, store_type="comments")

    async def store_creator(self, creator: Dict):
        """
        Douyin creator CSV storage implementation
        Args:
            creator: creator item dict

        Returns:

        """
        await self.save_data_to_csv(save_item=creator, store_type="creator")


class DouyinDbStoreImplement(AbstractStore):
    async def store_content(self, content_item: Dict):
        """
        Douyin content DB storage implementation
        Args:
            content_item: content item dict

        Returns:

        """

        from .douyin_store_sql import (add_new_content,
                                       query_content_by_content_id,
                                       update_content_by_content_id)
        aweme_id = content_item.get("aweme_id")
        aweme_detail: Dict = await query_content_by_content_id(content_id=aweme_id)
        task_id = content_item.get("task_id")
        if not aweme_detail:
            content_item["add_ts"] = utils.get_current_timestamp()
            if content_item.get("title"):
                await add_new_content(content_item, task_id=task_id)
        else:
            await update_content_by_content_id(aweme_id, content_item=content_item)

    async def store_comment(self, comment_item: Dict):
        """
        Douyin content DB storage implementation
        Args:
            comment_item: comment item dict

        Returns:

        """
        from .douyin_store_sql import (add_new_comment,
                                       query_comment_by_comment_id,
                                       update_comment_by_comment_id)
        comment_id = comment_item.get("comment_id")
        comment_detail: Dict = await query_comment_by_comment_id(comment_id=comment_id)
        if not comment_detail:
            comment_item["add_ts"] = utils.get_current_timestamp()
            await add_new_comment(comment_item)
        else:
            await update_comment_by_comment_id(comment_id, comment_item=comment_item)

    async def store_creator(self, creator: Dict):
        """
        Douyin content DB storage implementation
        Args:
            creator: creator dict

        Returns:

        """
        from .douyin_store_sql import (add_new_creator,
                                       query_creator_by_user_id,
                                       update_creator_by_user_id)
        user_id = creator.get("user_id")
        user_detail: Dict = await query_creator_by_user_id(user_id)
        if not user_detail:
            creator["add_ts"] = utils.get_current_timestamp()
            await add_new_creator(creator)
        else:
            await update_creator_by_user_id(user_id, creator)

class DouyinJsonStoreImplement(AbstractStore):
    json_store_path: str = "data/douyin/json"
    words_store_path: str = "data/douyin/words"

    lock = asyncio.Lock()
    file_count: int = calculate_number_of_files(json_store_path)
    WordCloud = words.AsyncWordCloudGenerator()

    def make_save_file_name(self, store_type: str) -> (str,str):
        """
        make save file name by store type
        Args:
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns:

        """

        return (
            f"{self.json_store_path}/{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}.json",
            f"{self.words_store_path}/{crawler_type_var.get()}_{store_type}_{utils.get_current_date()}"
        )
    async def save_data_to_json(self, save_item: Dict, store_type: str):
        """
        Below is a simple way to save it in json format.
        Args:
            save_item: save content dict info
            store_type: Save type contains content and commentsï¼ˆcontents | commentsï¼‰

        Returns:

        """
        pathlib.Path(self.json_store_path).mkdir(parents=True, exist_ok=True)
        pathlib.Path(self.words_store_path).mkdir(parents=True, exist_ok=True)
        save_file_name,words_file_name_prefix = self.make_save_file_name(store_type=store_type)
        save_data = []

        async with self.lock:
            if os.path.exists(save_file_name):
                async with aiofiles.open(save_file_name, 'r', encoding='utf-8') as file:
                    save_data = json.loads(await file.read())

            save_data.append(save_item)
            async with aiofiles.open(save_file_name, 'w', encoding='utf-8') as file:
                await file.write(json.dumps(save_data, ensure_ascii=False))

            if config.ENABLE_GET_COMMENTS and config.ENABLE_GET_WORDCLOUD:
                try:
                    await self.WordCloud.generate_word_frequency_and_cloud(save_data, words_file_name_prefix)
                except:
                    pass

    async def store_content(self, content_item: Dict):
        """
        content JSON storage implementation
        Args:
            content_item:

        Returns:

        """
        await self.save_data_to_json(content_item, "contents")

    async def store_comment(self, comment_item: Dict):
        """
        comment JSON storage implementation
        Args:
            comment_item:

        Returns:

        """
        await self.save_data_to_json(comment_item, "comments")


    async def store_creator(self, creator: Dict):
        """
        Douyin creator CSV storage implementation
        Args:
            creator: creator item dict

        Returns:

        """
        await self.save_data_to_json(save_item=creator, store_type="creator")


class DouyinRedisStoreImplement(AbstractStore):
    """æŠ–éŸ³Rediså­˜å‚¨å®ç°"""
    
    def __init__(self, redis_callback=None):
        self.redis_callback = redis_callback
        self.collected_data = []  # æ”¶é›†çˆ¬å–åˆ°çš„æ•°æ®
    
    def set_redis_callback(self, callback):
        """è®¾ç½®Rediså›è°ƒå‡½æ•°"""
        self.redis_callback = callback
    
    def _extract_video_download_url(self, aweme_detail: Dict) -> str:
        """
        æå–è§†é¢‘ä¸‹è½½åœ°å€

        Args:
            aweme_detail (Dict): æŠ–éŸ³è§†é¢‘

        Returns:
            str: è§†é¢‘ä¸‹è½½åœ°å€
        """
        video_item = aweme_detail.get("video", {})
        url_h264_list = video_item.get("play_addr_h264", {}).get("url_list", [])
        url_256_list = video_item.get("play_addr_256", {}).get("url_list", [])
        url_list = video_item.get("play_addr", {}).get("url_list", [])
        actual_url_list = url_h264_list or url_256_list or url_list
        if not actual_url_list or len(actual_url_list) < 2:
            return ""
        return actual_url_list[-1]
    
    def _extract_content_cover_url(self, aweme_detail: Dict) -> str:
        """
        æå–è§†é¢‘å°é¢åœ°å€

        Args:
            aweme_detail (Dict): æŠ–éŸ³å†…å®¹è¯¦æƒ…

        Returns:
            str: è§†é¢‘å°é¢åœ°å€
        """
        res_cover_url = ""

        video_item = aweme_detail.get("video", {})
        raw_cover_url_list = (
                video_item.get("raw_cover", {}) or video_item.get("origin_cover", {})
        ).get("url_list", [])
        if raw_cover_url_list and len(raw_cover_url_list) > 1:
            res_cover_url = raw_cover_url_list[1]

        return res_cover_url
    
    async def store_content(self, content_item: Dict):
        """
        æŠ–éŸ³å†…å®¹Rediså­˜å‚¨å®ç°ï¼ˆæ ‡å‡†åŒ–å­—æ®µï¼‰
        Args:
            content_item: è§†é¢‘å†…å®¹å­—å…¸
        """
        # å…¼å®¹ä¸åŒå­—æ®µæ¥æº
        aweme_id = content_item.get("aweme_id") or content_item.get("video_id")
        user_info = content_item.get("author", {})
        interact_info = content_item.get("statistics", {})

        processed_content = {
            "aweme_id": aweme_id,
            "aweme_url": f"https://www.douyin.com/video/{aweme_id}",  # å¿…é¡»
            "download_url": self._extract_video_download_url(content_item),  # æœ‰åˆ™å­˜
            "cover_url": self._extract_content_cover_url(content_item),
            "title": content_item.get("desc", "") or content_item.get("title", ""),
            "author_id": user_info.get("uid") or content_item.get("author_id", ""),
            "author_name": user_info.get("nickname") or content_item.get("author_name", ""),
            "avatar": user_info.get("avatar_thumb", {}).get("url_list", [""])[0] if user_info.get("avatar_thumb") else "",
            "create_time": content_item.get("create_time"),
            "liked_count": str(interact_info.get("digg_count") or content_item.get("liked_count", "")),
            "comment_count": str(interact_info.get("comment_count") or content_item.get("comment_count", "")),
            "collected_count": str(interact_info.get("collect_count") or content_item.get("collected_count", "")),
            "share_count": str(interact_info.get("share_count") or content_item.get("share_count", "")),
            "platform": "dy",
            "source_keyword": content_item.get("source_keyword", ""),
            "task_id": content_item.get("task_id", ""),
            "stored_at": content_item.get("stored_at", ""),
        }

        # æ”¶é›†æ•°æ®ç”¨äºè¿”å›
        self.collected_data.append(processed_content)

        # æ—¥å¿—è¾“å‡º
        utils.logger.info(f"ğŸ¬ [DouyinRedisStore] è§†é¢‘ID: {aweme_id}, æ ‡é¢˜: {processed_content.get('title')}")
        utils.logger.info(f"ğŸ”— [DouyinRedisStore] æ’­æ”¾é¡µé“¾æ¥: {processed_content.get('aweme_url')}")
        utils.logger.info(f"ğŸ“¥ [DouyinRedisStore] ä¸‹è½½é“¾æ¥: {processed_content.get('download_url')}")

        # åŒæ—¶å­˜å‚¨åˆ°æ•°æ®åº“
        try:
            from .douyin_store_sql import (add_new_content,
                                           query_content_by_content_id,
                                           update_content_by_content_id)
            
            aweme_detail: Dict = await query_content_by_content_id(content_id=aweme_id)
            task_id = content_item.get("task_id")
            if not aweme_detail:
                content_item["add_ts"] = utils.get_current_timestamp()
                if content_item.get("title") or content_item.get("desc"):
                    await add_new_content(content_item, task_id=task_id)
                    utils.logger.info(f"âœ… [DouyinRedisStore] æ•°æ®å·²å­˜å‚¨åˆ°æ•°æ®åº“: {aweme_id}")
            else:
                await update_content_by_content_id(aweme_id, content_item=content_item)
                utils.logger.info(f"âœ… [DouyinRedisStore] æ•°æ®å·²æ›´æ–°åˆ°æ•°æ®åº“: {aweme_id}")
        except Exception as e:
            utils.logger.error(f"âŒ [DouyinRedisStore] æ•°æ®åº“å­˜å‚¨å¤±è´¥: {aweme_id}, é”™è¯¯: {e}")

        # å­˜å‚¨åˆ°Redis
        if self.redis_callback:
            await self.redis_callback("dy", processed_content, "video")

    async def store_comment(self, comment_item: Dict):
        """
        æŠ–éŸ³è¯„è®ºRediså­˜å‚¨å®ç°
        Args:
            comment_item: è¯„è®ºå­—å…¸
        """
        if self.redis_callback:
            await self.redis_callback("dy", comment_item, "comment")

    async def store_creator(self, creator: Dict):
        """
        æŠ–éŸ³åˆ›ä½œè€…Rediså­˜å‚¨å®ç°
        Args:
            creator: åˆ›ä½œè€…å­—å…¸
        """
        if self.redis_callback:
            await self.redis_callback("dy", creator, "creator")

    async def get_all_content(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å­˜å‚¨çš„å†…å®¹
        Returns:
            List[Dict]: å†…å®¹åˆ—è¡¨
        """
        utils.logger.info(f"[DouyinRedisStore] è·å–å­˜å‚¨å†…å®¹ - å…±æ”¶é›†åˆ° {len(self.collected_data)} æ¡æ•°æ®")
        return self.collected_data