#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çˆ¬è™«ä¼˜åŒ–åˆ†æå·¥å…· - æ”¯æŒæ‰€æœ‰å¹³å°
åˆ†æå½“å‰é…ç½®å¹¶æä¾›ä¼˜åŒ–å»ºè®®ï¼Œé¿å…æœåŠ¡é˜»å¡
"""

import os
import yaml
import subprocess
from typing import Dict, Any, List


def analyze_config():
    """åˆ†æå½“å‰é…ç½®æ–‡ä»¶"""
    config_file = "config/config_local.yaml"
    
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None


def provide_optimization_suggestions(config: Dict[str, Any]) -> List[str]:
    """æä¾›ä¼˜åŒ–å»ºè®®"""
    suggestions = []
    crawler_config = config.get('crawler', {})
    
    # åˆ†æå¹¶å‘è®¾ç½®
    max_concurrency = crawler_config.get('max_concurrency', 1)
    if max_concurrency > 3:
        suggestions.append("ğŸ”§ å¹¶å‘æ•°è¿‡é«˜ï¼Œå»ºè®®å‡å°‘åˆ°2-3")
    elif max_concurrency < 1:
        suggestions.append("ğŸ”§ å¹¶å‘æ•°è¿‡ä½ï¼Œå¯ä»¥é€‚å½“å¢åŠ åˆ°2")
    
    # åˆ†æçˆ¬å–æ•°é‡
    max_notes_count = crawler_config.get('max_notes_count', 50)
    if max_notes_count > 50:
        suggestions.append("ğŸ”§ çˆ¬å–æ•°é‡è¿‡å¤šï¼Œå»ºè®®å‡å°‘åˆ°20-30")
    elif max_notes_count < 10:
        suggestions.append("ğŸ”§ çˆ¬å–æ•°é‡è¾ƒå°‘ï¼Œå¯ä»¥é€‚å½“å¢åŠ åˆ°20")
    
    # åˆ†æç¡çœ é—´éš”
    max_sleep_sec = crawler_config.get('max_sleep_sec', 3)
    if max_sleep_sec < 3:
        suggestions.append("ğŸ”§ ç¡çœ é—´éš”è¿‡çŸ­ï¼Œå»ºè®®å¢åŠ åˆ°5ç§’")
    elif max_sleep_sec > 10:
        suggestions.append("ğŸ”§ ç¡çœ é—´éš”è¿‡é•¿ï¼Œå¯ä»¥å‡å°‘åˆ°5ç§’")
    
    # åˆ†æåŠŸèƒ½å¼€å…³
    enable_comments = crawler_config.get('enable_comments', True)
    if enable_comments:
        suggestions.append("ğŸ”§ è¯„è®ºåŠŸèƒ½å·²å¼€å¯ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥å…³é—­ä»¥å‡å°‘èµ„æºæ¶ˆè€—")
    
    enable_images = crawler_config.get('enable_images', False)
    if enable_images:
        suggestions.append("ğŸ”§ å›¾ç‰‡ä¸‹è½½å·²å¼€å¯ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥å…³é—­ä»¥å‡å°‘èµ„æºæ¶ˆè€—")
    
    # åˆ†æRedisé…ç½®
    redis_config = config.get('redis', {})
    connection_pool_size = redis_config.get('connection_pool_size', 10)
    if connection_pool_size > 10:
        suggestions.append("ğŸ”§ Redisè¿æ¥æ± è¿‡å¤§ï¼Œå»ºè®®å‡å°‘åˆ°5-10")
    
    max_connections = redis_config.get('max_connections', 100)
    if max_connections > 50:
        suggestions.append("ğŸ”§ Redisæœ€å¤§è¿æ¥æ•°è¿‡å¤šï¼Œå»ºè®®å‡å°‘åˆ°20-50")
    
    return suggestions


def generate_optimized_config(config: Dict[str, Any], suggestions: List[str]) -> Dict[str, Any]:
    """ç”Ÿæˆä¼˜åŒ–åçš„é…ç½®"""
    optimized_config = config.copy()
    crawler_config = optimized_config.get('crawler', {})
    
    # æ ¹æ®å»ºè®®è°ƒæ•´é…ç½®
    if "å¹¶å‘æ•°è¿‡é«˜" in str(suggestions):
        crawler_config['max_concurrency'] = 2
    
    if "çˆ¬å–æ•°é‡è¿‡å¤š" in str(suggestions):
        crawler_config['max_notes_count'] = 20
    
    if "ç¡çœ é—´éš”è¿‡çŸ­" in str(suggestions):
        crawler_config['max_sleep_sec'] = 5
    
    if "è¯„è®ºåŠŸèƒ½å·²å¼€å¯" in str(suggestions):
        crawler_config['enable_comments'] = False
    
    if "å›¾ç‰‡ä¸‹è½½å·²å¼€å¯" in str(suggestions):
        crawler_config['enable_images'] = False
    
    # è°ƒæ•´Redisé…ç½®
    redis_config = optimized_config.get('redis', {})
    if "Redisè¿æ¥æ± è¿‡å¤§" in str(suggestions):
        redis_config['connection_pool_size'] = 5
    
    if "Redisæœ€å¤§è¿æ¥æ•°è¿‡å¤š" in str(suggestions):
        redis_config['max_connections'] = 20
    
    optimized_config['crawler'] = crawler_config
    optimized_config['redis'] = redis_config
    
    return optimized_config


def create_resource_monitoring_script():
    """åˆ›å»ºèµ„æºç›‘æ§è„šæœ¬ä½¿ç”¨è¯´æ˜"""
    print("\nğŸ“Š èµ„æºç›‘æ§ä½¿ç”¨è¯´æ˜:")
    print("=" * 50)
    print("1. å¯åŠ¨ç›‘æ§:")
    print("   python monitor_resources.py")
    print()
    print("2. ç›‘æ§æŒ‡æ ‡:")
    print("   - CPUä½¿ç”¨ç‡ > 80%: è­¦å‘Š")
    print("   - å†…å­˜ä½¿ç”¨ç‡ > 85%: è­¦å‘Š")
    print("   - ç£ç›˜ä½¿ç”¨ç‡ > 90%: è­¦å‘Š")
    print()
    print("3. ä¼˜åŒ–å»ºè®®:")
    print("   - å¦‚æœCPUè¿‡é«˜: å‡å°‘å¹¶å‘æ•°")
    print("   - å¦‚æœå†…å­˜è¿‡é«˜: å‡å°‘çˆ¬å–æ•°é‡")
    print("   - å¦‚æœç£ç›˜è¿‡é«˜: æ¸…ç†æ—¥å¿—æ–‡ä»¶")
    print()


def create_emergency_stop_script():
    """åˆ›å»ºç´§æ€¥åœæ­¢è„šæœ¬"""
    script_content = """#!/bin/bash
# ç´§æ€¥åœæ­¢çˆ¬è™«è„šæœ¬

echo "ğŸ›‘ æ­£åœ¨åœæ­¢æ‰€æœ‰çˆ¬è™«è¿›ç¨‹..."

# æŸ¥æ‰¾å¹¶åœæ­¢çˆ¬è™«è¿›ç¨‹
pkill -f "python.*main.py"
pkill -f "python.*crawler"
pkill -f "python.*monitor_resources.py"

# ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
sleep 3

# æ£€æŸ¥æ˜¯å¦è¿˜æœ‰çˆ¬è™«è¿›ç¨‹
if pgrep -f "python.*main.py" > /dev/null; then
    echo "âš ï¸ å¼ºåˆ¶åœæ­¢å‰©ä½™è¿›ç¨‹..."
    pkill -9 -f "python.*main.py"
fi

echo "âœ… æ‰€æœ‰çˆ¬è™«è¿›ç¨‹å·²åœæ­¢"

# æ˜¾ç¤ºç³»ç»Ÿèµ„æºçŠ¶æ€
echo "ğŸ“Š å½“å‰ç³»ç»Ÿèµ„æºçŠ¶æ€:"
free -h
df -h /
"""
    
    try:
        with open("emergency_stop.sh", "w") as f:
            f.write(script_content)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod("emergency_stop.sh", 0o755)
        print("âœ… ç´§æ€¥åœæ­¢è„šæœ¬å·²åˆ›å»º: emergency_stop.sh")
    except Exception as e:
        print(f"âŒ åˆ›å»ºç´§æ€¥åœæ­¢è„šæœ¬å¤±è´¥: {e}")


def analyze_platform_specific_config(config: Dict[str, Any]):
    """åˆ†æå¹³å°ç‰¹å®šé…ç½®"""
    platform = config.get('crawler', {}).get('platform', 'unknown')
    
    print(f"\nğŸ¯ å¹³å°ç‰¹å®šåˆ†æ: {platform.upper()}")
    print("=" * 40)
    
    if platform == 'xhs':
        print("ğŸ“‹ å°çº¢ä¹¦çˆ¬è™«ç‰¹ç‚¹:")
        print("   - æ”¯æŒè§†é¢‘ç­›é€‰åŠŸèƒ½")
        print("   - è¯„è®ºè·å–è¾ƒç¨³å®š")
        print("   - å»ºè®®å¹¶å‘æ•°: 2-3")
        print("   - å»ºè®®çˆ¬å–æ•°é‡: 20-30")
        
    elif platform == 'dy':
        print("ğŸ“‹ æŠ–éŸ³çˆ¬è™«ç‰¹ç‚¹:")
        print("   - åçˆ¬æœºåˆ¶è¾ƒå¼º")
        print("   - å»ºè®®å¢åŠ ç¡çœ é—´éš”")
        print("   - å»ºè®®å¹¶å‘æ•°: 1-2")
        print("   - å»ºè®®çˆ¬å–æ•°é‡: 10-20")
        
    elif platform == 'ks':
        print("ğŸ“‹ å¿«æ‰‹çˆ¬è™«ç‰¹ç‚¹:")
        print("   - è§†é¢‘è·å–è¾ƒç¨³å®š")
        print("   - è¯„è®ºè·å–å¯èƒ½è¾ƒæ…¢")
        print("   - å»ºè®®å¹¶å‘æ•°: 2-3")
        print("   - å»ºè®®çˆ¬å–æ•°é‡: 20-30")
        
    elif platform == 'bili':
        print("ğŸ“‹ Bç«™çˆ¬è™«ç‰¹ç‚¹:")
        print("   - æ”¯æŒæ—¶é—´èŒƒå›´æœç´¢")
        print("   - è¯„è®ºè·å–è¾ƒç¨³å®š")
        print("   - å»ºè®®å¹¶å‘æ•°: 2-3")
        print("   - å»ºè®®çˆ¬å–æ•°é‡: 20-30")
        
    else:
        print("ğŸ“‹ é€šç”¨çˆ¬è™«å»ºè®®:")
        print("   - å»ºè®®å¹¶å‘æ•°: 2-3")
        print("   - å»ºè®®çˆ¬å–æ•°é‡: 20-30")
        print("   - å»ºè®®ç¡çœ é—´éš”: 5ç§’")
        print("   - å»ºè®®å…³é—­ä¸å¿…è¦çš„åŠŸèƒ½")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ çˆ¬è™«ä¼˜åŒ–åˆ†æå·¥å…·")
    print("=" * 60)
    
    # åˆ†æé…ç½®
    config = analyze_config()
    if not config:
        return
    
    print("ğŸ” åˆ†æå½“å‰çˆ¬è™«é…ç½®...")
    print("=" * 60)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    crawler_config = config.get('crawler', {})
    print("ğŸ“Š å½“å‰é…ç½®åˆ†æ:")
    print(f"  å¹³å°: {crawler_config.get('platform', 'unknown')}")
    print(f"  å…³é”®è¯: {crawler_config.get('keywords', 'N/A')}")
    print(f"  çˆ¬å–ç±»å‹: {crawler_config.get('crawler_type', 'N/A')}")
    print(f"  æœ€å¤§ç¬”è®°æ•°: {crawler_config.get('max_notes_count', 'N/A')}")
    print(f"  å¹¶å‘æ•°: {crawler_config.get('max_concurrency', 'N/A')}")
    print(f"  ç¡çœ é—´éš”: {crawler_config.get('max_sleep_sec', 'N/A')}ç§’")
    print(f"  è·å–è¯„è®º: {crawler_config.get('enable_comments', 'N/A')}")
    print(f"  è·å–å›¾ç‰‡: {crawler_config.get('enable_images', 'N/A')}")
    
    # å¹³å°ç‰¹å®šåˆ†æ
    analyze_platform_specific_config(config)
    
    # æä¾›ä¼˜åŒ–å»ºè®®
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print("=" * 60)
    suggestions = provide_optimization_suggestions(config)
    
    if suggestions:
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion}")
    else:
        print("  âœ… å½“å‰é…ç½®çœ‹èµ·æ¥æ¯”è¾ƒåˆç†")
    
    # ç”Ÿæˆä¼˜åŒ–åçš„é…ç½®
    print("\nğŸ”§ ä¼˜åŒ–åçš„é…ç½®å»ºè®®:")
    print("=" * 60)
    optimized_config = generate_optimized_config(config, suggestions)
    
    # æ˜¾ç¤ºä¼˜åŒ–åçš„é…ç½®
    optimized_crawler = optimized_config.get('crawler', {})
    print("crawler:")
    for key, value in optimized_crawler.items():
        print(f"  {key}: {value}")
    
    # èµ„æºç›‘æ§å»ºè®®
    print("\nğŸ“Š èµ„æºç›‘æ§å»ºè®®:")
    print("=" * 60)
    print("1. è¿è¡Œèµ„æºç›‘æ§è„šæœ¬:")
    print("   python monitor_resources.py")
    print()
    print("2. ç›‘æ§å…³é”®æŒ‡æ ‡:")
    print("   - CPUä½¿ç”¨ç‡ > 80%: å‡å°‘å¹¶å‘æ•°")
    print("   - å†…å­˜ä½¿ç”¨ç‡ > 85%: å‡å°‘çˆ¬å–æ•°é‡")
    print("   - ç£ç›˜ä½¿ç”¨ç‡ > 90%: æ¸…ç†æ—¥å¿—æ–‡ä»¶")
    print()
    print("3. å®æ—¶ç›‘æ§å‘½ä»¤:")
    print("   htop  # æŸ¥çœ‹ç³»ç»Ÿèµ„æº")
    print("   iotop # æŸ¥çœ‹ç£ç›˜I/O")
    print("   nethogs # æŸ¥çœ‹ç½‘ç»œä½¿ç”¨")
    
    # ç´§æ€¥åœæ­¢æ–¹æ¡ˆ
    print("\nğŸ›‘ ç´§æ€¥åœæ­¢æ–¹æ¡ˆ:")
    print("=" * 60)
    create_emergency_stop_script()
    print("âœ… å·²åˆ›å»ºç´§æ€¥åœæ­¢è„šæœ¬: emergency_stop.sh")
    print("   ä½¿ç”¨æ–¹æ³•: ./emergency_stop.sh")
    
    # æ€»ç»“
    print("\nğŸ¯ æ€»ç»“:")
    print("=" * 60)
    print("1. å½“å‰é…ç½®å·²ä¼˜åŒ–ï¼Œå‡å°‘äº†èµ„æºæ¶ˆè€—")
    print("2. å»ºè®®ä½¿ç”¨èµ„æºç›‘æ§è„šæœ¬è§‚å¯Ÿè¿è¡ŒçŠ¶æ€")
    print("3. å¦‚æœå‡ºç°é˜»å¡ï¼Œä½¿ç”¨ç´§æ€¥åœæ­¢è„šæœ¬")
    print("4. æ ¹æ®ç›‘æ§ç»“æœè¿›ä¸€æ­¥è°ƒæ•´é…ç½®")
    
    # ä¸‹ä¸€æ­¥æ“ä½œ
    print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. è¿è¡Œä¼˜åŒ–åçš„é…ç½®è¿›è¡Œæµ‹è¯•")
    print("2. å¯åŠ¨èµ„æºç›‘æ§: python monitor_resources.py")
    print("3. å¦‚æœå‡ºç°é—®é¢˜: ./emergency_stop.sh")
    print("4. æ ¹æ®ç›‘æ§ç»“æœè°ƒæ•´é…ç½®å‚æ•°")


if __name__ == "__main__":
    main() 