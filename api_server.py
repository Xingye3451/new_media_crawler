"""
MediaCrawler API æœåŠ¡å™¨
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import ValidationError as RequestValidationError
from datetime import datetime, timedelta
import asyncio
import os
from pathlib import Path

import utils
import db
from tools.time_util import get_isoformat_utc8
from var import media_crawler_db_var
from models.content_models import (
    CrawlerRequest, CrawlerResponse, TaskStatusResponse,
    MultiPlatformCrawlerRequest, MultiPlatformTaskStatusResponse,
    ContentListRequest, ContentListResponse, UnifiedContent
)

# å¯¼å…¥APIè·¯ç”±
from api.routes import api_router

# é¢„ç•™ï¼šå¯¼å…¥è®¤è¯ä¸­é—´ä»¶
from middleware.auth_middleware import auth_middleware, enable_auth_middleware, disable_auth_middleware

def get_app_version():
    """è·å–åº”ç”¨ç‰ˆæœ¬ä¿¡æ¯"""
    try:
        # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è·å–ç‰ˆæœ¬
        env_version = os.environ.get('APP_VERSION')
        if env_version:
            return env_version
        
        # ç„¶åå°è¯•ä» VERSION æ–‡ä»¶è¯»å–
        version_file = Path("VERSION")
        if version_file.exists():
            with open(version_file, 'r', encoding='utf-8') as f:
                version = f.read().strip()
                return version
        
        # æœ€åä½¿ç”¨é»˜è®¤ç‰ˆæœ¬
        return "v1.0.0"
    except Exception as e:
        utils.logger.warning(f"æ— æ³•è¯»å–ç‰ˆæœ¬ä¿¡æ¯: {e}")
        return "v1.0.0"

def get_build_info():
    """è·å–æ„å»ºä¿¡æ¯"""
    return {
        "version": get_app_version(),
        "build_date": os.environ.get('BUILD_DATE', 'unknown'),
        "git_commit": os.environ.get('VCS_REF', 'unknown'),
        "environment": os.environ.get('ENV', 'development')
    }

# è·å–ç‰ˆæœ¬ä¿¡æ¯
app_version = get_app_version()
build_info = get_build_info()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="MediaCrawler API",
    description="å¤šå¹³å°åª’ä½“å†…å®¹çˆ¬è™«APIæœåŠ¡",
    version=app_version,
    docs_url="/docs",
    redoc_url="/redoc"
)

# é¢„ç•™ï¼šæ·»åŠ è®¤è¯ä¸­é—´ä»¶ï¼ˆå½“å‰ç¦ç”¨ï¼‰
# app.middleware("http")(auth_middleware)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/images", StaticFiles(directory="static/images"), name="images")


# å…¨å±€å˜é‡
task_status = {}
multi_platform_task_status = {}


async def cleanup_old_logs():
    """æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶"""
    try:
        logs_dir = Path("logs")
        if not logs_dir.exists():
            return
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä¿ç•™å¤©æ•°
        retention_days = 15  # é»˜è®¤å€¼
        try:
            from config.config_manager import config_manager
            retention_days = config_manager.get("logging.retention_days", 15)
        except Exception as e:
            utils.logger.warning(f"æ— æ³•ä»é…ç½®æ–‡ä»¶è¯»å–æ—¥å¿—ä¿ç•™å¤©æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼15å¤©: {e}")
        
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        deleted_count = 0
        total_size = 0
        
        utils.logger.debug(f"å¼€å§‹æ¸…ç†è¿‡æœŸæ—¥å¿—æ–‡ä»¶ï¼Œä¿ç•™å¤©æ•°: {retention_days}")
        
        for log_file in logs_dir.glob("*.log"):
            try:
                # å°è¯•ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ
                file_date_str = log_file.stem.split('_')[-1] if '_' in log_file.stem else None
                should_delete = False
                
                if file_date_str:
                    try:
                        file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
                        should_delete = file_date < cutoff_date
                    except ValueError:
                        # å¦‚æœæ— æ³•è§£ææ—¥æœŸï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                        file_mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                        should_delete = file_mtime < cutoff_date
                else:
                    # å¦‚æœæ–‡ä»¶åä¸­æ²¡æœ‰æ—¥æœŸï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    file_mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                    should_delete = file_mtime < cutoff_date
                
                if should_delete:
                    file_size = log_file.stat().st_size
                    log_file.unlink()
                    deleted_count += 1
                    total_size += file_size
                    utils.logger.debug(f"å·²åˆ é™¤è¿‡æœŸæ—¥å¿—æ–‡ä»¶: {log_file.name} (å¤§å°: {file_size / 1024 / 1024:.2f}MB)")
                
            except Exception as e:
                utils.logger.error(f"å¤„ç†æ—¥å¿—æ–‡ä»¶ {log_file} æ—¶å‡ºé”™: {e}")
        
        if deleted_count > 0:
            utils.logger.info(f"æ—¥å¿—æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªè¿‡æœŸæ–‡ä»¶ï¼Œé‡Šæ”¾ç©ºé—´: {total_size / 1024 / 1024:.2f}MB")
        else:
            utils.logger.debug("æ²¡æœ‰éœ€è¦æ¸…ç†çš„è¿‡æœŸæ—¥å¿—æ–‡ä»¶")
            
    except Exception as e:
        utils.logger.error(f"æ¸…ç†æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")


async def log_cleanup_scheduler():
    """æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡"""
    while True:
        try:
            # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªå‡Œæ™¨çš„æ—¶é—´
            now = datetime.now()
            next_run = now.replace(hour=2, minute=0, second=0, microsecond=0)  # å‡Œæ™¨2ç‚¹æ‰§è¡Œ
            if next_run <= now:
                next_run += timedelta(days=1)
            
            # ç­‰å¾…åˆ°ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            wait_seconds = (next_run - now).total_seconds()
            utils.logger.debug(f"æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡å°†åœ¨ {next_run.strftime('%Y-%m-%d %H:%M:%S')} æ‰§è¡Œ")
            await asyncio.sleep(wait_seconds)
            
            # æ‰§è¡Œæ—¥å¿—æ¸…ç†
            await cleanup_old_logs()
            
        except Exception as e:
            utils.logger.error(f"æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡å‡ºé”™: {e}")
            # å‡ºé”™åç­‰å¾…1å°æ—¶å†é‡è¯•
            await asyncio.sleep(3600)


# å¼‚å¸¸å¤„ç†å™¨
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """è¯·æ±‚éªŒè¯å¼‚å¸¸å¤„ç†å™¨"""
    return JSONResponse(
        status_code=422,
        content={
            "detail": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            "errors": exc.errors(),
            "timestamp": get_isoformat_utc8()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """é€šç”¨å¼‚å¸¸å¤„ç†å™¨"""
    utils.logger.error(f"æœªå¤„ç†çš„å¼‚å¸¸: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "detail": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
            "error": str(exc),
            "timestamp": get_isoformat_utc8()
        }
    )

# æ³¨å†ŒAPIè·¯ç”±
app.include_router(api_router, prefix="/api")

# åº”ç”¨å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    try:
        # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
        utils.logger.info("ğŸš€ MediaCrawler API æœåŠ¡å¯åŠ¨ä¸­...")
        utils.logger.debug(f"ğŸ“¦ ç‰ˆæœ¬ä¿¡æ¯:")
        utils.logger.debug(f"   - åº”ç”¨ç‰ˆæœ¬: {build_info['version']}")
        utils.logger.debug(f"   - æ„å»ºæ—¥æœŸ: {build_info['build_date']}")
        utils.logger.debug(f"   - Gitæäº¤: {build_info['git_commit']}")
        utils.logger.debug(f"   - è¿è¡Œç¯å¢ƒ: {build_info['environment']}")
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await db.init_db()
        utils.logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–Redisè¿æ¥
        from utils.redis_manager import TaskResultRedisManager
        redis_manager = TaskResultRedisManager()
        await redis_manager.ping()
        utils.logger.info("âœ… Redisè¿æ¥åˆå§‹åŒ–å®Œæˆ")
        
        # ğŸ†• å¯åŠ¨ä»»åŠ¡æ¸…ç†æœºåˆ¶
        try:
            from api.task_cleanup_init import init_task_cleanup
            await init_task_cleanup()
            utils.logger.debug("âœ… ä»»åŠ¡æ¸…ç†æœºåˆ¶åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ ä»»åŠ¡æ¸…ç†æœºåˆ¶åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ğŸ†• å¯åŠ¨ä»»åŠ¡éš”ç¦»ç®¡ç†å™¨
        try:
            from utils.task_isolation import task_isolation_manager, start_task_cleanup
            import asyncio
            asyncio.create_task(start_task_cleanup())
            utils.logger.debug("âœ… ä»»åŠ¡éš”ç¦»ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ ä»»åŠ¡éš”ç¦»ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ğŸ†• å¯åŠ¨æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡
        try:
            asyncio.create_task(log_cleanup_scheduler())
            utils.logger.debug("âœ… æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œï¼‰")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ æ—¥å¿—æ¸…ç†å®šæ—¶ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
        
        # ğŸ†• å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
        try:
            from timetask.task_scheduler import scheduler
            await scheduler.start()
            utils.logger.debug("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {e}")
        
        # åŠ è½½é…ç½®
        from config.env_config_loader import config_loader
        env = config_loader.get_environment()
        utils.logger.debug(f"âœ… é…ç½®åŠ è½½å®Œæˆï¼Œç¯å¢ƒ: {env}")
        
        # ğŸ†• é¢„ç•™ï¼šé…ç½®è®¤è¯ä¸­é—´ä»¶
        try:
            from config.base_config import AUTH_MIDDLEWARE_ENABLED
            if AUTH_MIDDLEWARE_ENABLED:
                enable_auth_middleware()
                utils.logger.debug("âœ… è®¤è¯ä¸­é—´ä»¶å·²å¯ç”¨")
            else:
                utils.logger.debug("â„¹ï¸ è®¤è¯ä¸­é—´ä»¶å·²ç¦ç”¨ï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ è®¤è¯ä¸­é—´ä»¶é…ç½®å¤±è´¥: {e}")
        
        utils.logger.info("ğŸ‰ MediaCrawler API æœåŠ¡å¯åŠ¨å®Œæˆ!")
        
    except Exception as e:
        utils.logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise

# åº”ç”¨å…³é—­äº‹ä»¶
@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    try:
        utils.logger.info("ğŸ›‘ MediaCrawler API æœåŠ¡å…³é—­ä¸­...")
        
        # å…³é—­æ•°æ®åº“è¿æ¥
        await db.close()
        utils.logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
        
        # å…³é—­Redisè¿æ¥
        from utils.redis_manager import TaskResultRedisManager
        redis_manager = TaskResultRedisManager()
        await redis_manager.close()
        utils.logger.info("âœ… Redisè¿æ¥å·²å…³é—­")
        
        # ğŸ†• åœæ­¢å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
        try:
            from timetask.task_scheduler import scheduler
            await scheduler.stop()
            utils.logger.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
        except Exception as e:
            utils.logger.warning(f"âš ï¸ åœæ­¢å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")
        
        utils.logger.info("ğŸ‘‹ MediaCrawler API æœåŠ¡å·²å…³é—­")
        
    except Exception as e:
        utils.logger.error(f"âŒ æœåŠ¡å…³é—­æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# æ ¹è·¯å¾„
@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - è¿”å›ä¸»é¡µ"""
    return FileResponse("static/index.html")

# ä»»åŠ¡è¯¦æƒ…é¡µé¢
@app.get("/task_detail.html")
async def task_detail_page():
    """ä»»åŠ¡è¯¦æƒ…é¡µé¢"""
    return FileResponse("static/task_detail.html")

# ä»»åŠ¡ç»“æœé¡µé¢
@app.get("/task_results.html")
async def task_results_page():
    """ä»»åŠ¡ç»“æœé¡µé¢"""
    return FileResponse("static/task_results.html")

# è´¦å·ç®¡ç†é¡µé¢
@app.get("/account_management.html")
async def account_management_page():
    """è´¦å·ç®¡ç†é¡µé¢"""
    return FileResponse("static/account_management.html")

# è§†é¢‘é¢„è§ˆé¡µé¢
@app.get("/video_preview.html")
async def video_preview_page():
    """è§†é¢‘é¢„è§ˆé¡µé¢"""
    return FileResponse("static/video_preview.html")

# æ–‡ä»¶ç®¡ç†é¡µé¢ (å·²æ›¿æ¢ä¸ºè§†é¢‘æ”¶è—ç®¡ç†)
@app.get("/file_management.html")
async def file_management_page():
    """æ–‡ä»¶ç®¡ç†é¡µé¢ - é‡å®šå‘åˆ°è§†é¢‘æ”¶è—"""
    return FileResponse("static/video_favorites.html")

# APIæµ‹è¯•é¡µé¢
@app.get("/api_test.html")
async def api_test_page():
    """APIæµ‹è¯•é¡µé¢"""
    return FileResponse("static/api_test.html")

# APIä¿¡æ¯è·¯å¾„
@app.get("/api-info")
async def api_info():
    """APIä¿¡æ¯è·¯å¾„ - è¿”å›APIä¿¡æ¯"""
    return {
        "name": "MediaCrawler API",
        "version": build_info['version'],
        "description": "å¤šå¹³å°åª’ä½“å†…å®¹çˆ¬è™«APIæœåŠ¡",
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "build_info": build_info,
        "docs": "/docs",
        "redoc": "/redoc"
    }

# ç‰ˆæœ¬ä¿¡æ¯è·¯å¾„
@app.get("/version")
async def version_info():
    """ç‰ˆæœ¬ä¿¡æ¯è·¯å¾„ - è¿”å›è¯¦ç»†çš„ç‰ˆæœ¬ä¿¡æ¯"""
    return {
        "version": build_info['version'],
        "build_date": build_info['build_date'],
        "git_commit": build_info['git_commit'],
        "environment": build_info['environment'],
        "timestamp": datetime.now().isoformat()
    }

# å¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        db_status = "unknown"
        try:
            # ç›´æ¥åˆ›å»ºæ•°æ®åº“è¿æ¥è¿›è¡Œæµ‹è¯•
            from config.env_config_loader import config_loader
            from async_db import AsyncMysqlDB
            import aiomysql
            
            db_config = config_loader.get_database_config()
            
            pool = await aiomysql.create_pool(
                host=db_config['host'],
                port=db_config['port'],
                user=db_config['username'],
                password=db_config['password'],
                db=db_config['database'],
                autocommit=True,
                minsize=1,
                maxsize=5,
            )
            
            async_db_obj = AsyncMysqlDB(pool)
            await async_db_obj.query("SELECT 1")
            await pool.close()
            db_status = "connected"
            
        except Exception as e:
            db_status = f"error: {str(e)}"
        
        # æ£€æŸ¥Redisè¿æ¥
        redis_status = "unknown"
        try:
            from utils.redis_manager import TaskResultRedisManager
            redis_manager = TaskResultRedisManager()
            await redis_manager.ping()
            redis_status = "connected"
        except Exception as e:
            redis_status = f"error: {str(e)}"
        
        overall_status = "healthy" if all(
            status == "connected" 
            for status in [db_status, redis_status]
        ) else "unhealthy"
        
        return {
            "status": overall_status,
            "version": build_info['version'],
            "timestamp": datetime.now().isoformat(),
            "components": {
                "database": db_status,
                "redis": redis_status
            }
        }
        
    except Exception as e:
        utils.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "error",
            "version": build_info['version'],
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ä¸»å‡½æ•°
if __name__ == "__main__":
    import uvicorn
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
    print("ğŸš€ MediaCrawler API æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print(f"ğŸ“¦ ç‰ˆæœ¬: {build_info['version']}")
    print("=" * 40)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 