"""
Curlè§†é¢‘ä»£ç†æœåŠ¡
ä½¿ç”¨curlå‘½ä»¤æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚ï¼Œç»•è¿‡é˜²ç›—é“¾
"""

import subprocess
import os
import hashlib
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import FileResponse, StreamingResponse
from typing import Optional
import logging
from urllib.parse import urlparse
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

router = APIRouter()

# æœ¬åœ°è§†é¢‘å­˜å‚¨ç›®å½•
VIDEO_CACHE_DIR = "data/video_cache"
os.makedirs(VIDEO_CACHE_DIR, exist_ok=True)

# çº¿ç¨‹æ± æ‰§è¡Œå™¨
executor = ThreadPoolExecutor(max_workers=4)

def get_video_filename(url: str) -> str:
    """æ ¹æ®URLç”Ÿæˆæ–‡ä»¶å"""
    url_hash = hashlib.md5(url.encode()).hexdigest()
    return f"{url_hash}.mp4"

def get_video_path(url: str) -> str:
    """è·å–è§†é¢‘æœ¬åœ°è·¯å¾„"""
    filename = get_video_filename(url)
    return os.path.join(VIDEO_CACHE_DIR, filename)

def download_with_curl(url: str, file_path: str, is_video: bool = True):
    """ä½¿ç”¨curlä¸‹è½½æ–‡ä»¶"""
    try:
        # æ„å»ºcurlå‘½ä»¤ï¼Œä½¿ç”¨æ›´ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•
        curl_cmd = [
            'curl',
            '-L',  # è·Ÿéšé‡å®šå‘
            '-o', file_path,  # è¾“å‡ºæ–‡ä»¶
            '--compressed',  # æ”¯æŒå‹ç¼©
            '--retry', '3',  # ğŸ†• æ·»åŠ é‡è¯•æœºåˆ¶
            '--retry-delay', '1',  # ğŸ†• é‡è¯•å»¶è¿Ÿ1ç§’
            '--retry-max-time', '10',  # ğŸ†• æœ€å¤§é‡è¯•æ—¶é—´10ç§’
            '-H', 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            '-H', 'Accept: */*' if is_video else 'image/webp,image/apng,image/*,*/*;q=0.8',
            '-H', 'Accept-Language: zh-CN,zh;q=0.9,en;q=0.8',
            '-H', 'Accept-Encoding: gzip, deflate, br',
            '-H', 'Connection: keep-alive',
            '-H', 'Upgrade-Insecure-Requests: 1',
            '-H', 'Sec-Fetch-Dest: ' + ('video' if is_video else 'image'),
            '-H', 'Sec-Fetch-Mode: no-cors',
            '-H', 'Sec-Fetch-Site: cross-site',
        ]
        
        # è®¾ç½®Referer - è¿™æ˜¯å…³é”®
        if 'douyin' in url:
            curl_cmd.extend([
                '-H', 'Referer: https://www.douyin.com/',
                '-H', 'Origin: https://www.douyin.com',
            ])
        elif 'xiaohongshu' in url or 'xhscdn' in url:
            curl_cmd.extend([
                '-H', 'Referer: https://www.xiaohongshu.com/',
                '-H', 'Origin: https://www.xiaohongshu.com',
                '-H', 'X-Requested-With: XMLHttpRequest',
                '-H', 'Cache-Control: no-cache',
                '-H', 'Pragma: no-cache',
            ])
        else:
            parsed_url = urlparse(url)
            curl_cmd.extend(['-H', f'Referer: {parsed_url.scheme}://{parsed_url.netloc}/'])
        
        # è®¾ç½®è¶…æ—¶
        timeout = 30 if is_video else 10
        curl_cmd.extend(['--max-time', str(timeout)])
        
        # æ·»åŠ URL
        curl_cmd.append(url)
        
        logger.info(f"å¼€å§‹ä½¿ç”¨curlä¸‹è½½{'è§†é¢‘' if is_video else 'å›¾ç‰‡'}: {url}")
        
        # æ‰§è¡Œcurlå‘½ä»¤
        result = subprocess.run(
            curl_cmd,
            capture_output=True,
            text=True,
            timeout=timeout + 5
        )
        
        if result.returncode == 0 and os.path.exists(file_path) and os.path.getsize(file_path) > (100 if is_video else 100):  # ç¡®ä¿æ–‡ä»¶å¤§å°åˆç†
            logger.info(f"{'è§†é¢‘' if is_video else 'å›¾ç‰‡'}ä¸‹è½½å®Œæˆ: {file_path}, å¤§å°: {os.path.getsize(file_path)} å­—èŠ‚")
            return True
        else:
            logger.error(f"curlä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            logger.error(f"æ ‡å‡†è¾“å‡º: {result.stdout}")
            logger.error(f"æ–‡ä»¶å­˜åœ¨: {os.path.exists(file_path)}")
            if os.path.exists(file_path):
                logger.error(f"æ–‡ä»¶å¤§å°: {os.path.getsize(file_path)} å­—èŠ‚")
                # ğŸ†• æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶å†…å®¹
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read(500)
                        if '403' in content or 'Forbidden' in content:
                            logger.error("ä¸‹è½½çš„æ˜¯403é”™è¯¯é¡µé¢ï¼Œä¸æ˜¯è§†é¢‘æ–‡ä»¶")
                        elif '404' in content or 'Not Found' in content:
                            logger.error("ä¸‹è½½çš„æ˜¯404é”™è¯¯é¡µé¢ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                        elif '500' in content or 'Internal Server Error' in content:
                            logger.error("ä¸‹è½½çš„æ˜¯500é”™è¯¯é¡µé¢ï¼ŒæœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
                        else:
                            logger.error(f"ä¸‹è½½çš„å†…å®¹å‰500å­—ç¬¦: {content[:200]}...")
                except UnicodeDecodeError:
                    # å¦‚æœæ–‡ä»¶æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ£€æŸ¥æ–‡ä»¶å¤´
                    with open(file_path, 'rb') as f:
                        header = f.read(20)
                        if header.startswith(b'<!DOCTYPE') or header.startswith(b'<html'):
                            logger.error("ä¸‹è½½çš„æ˜¯HTMLé¡µé¢ï¼Œä¸æ˜¯è§†é¢‘æ–‡ä»¶")
                        elif header.startswith(b'\xff\xd8\xff'):  # JPEGæ–‡ä»¶å¤´
                            logger.info("ä¸‹è½½çš„æ˜¯æœ‰æ•ˆçš„JPEGå›¾ç‰‡")
                        elif header.startswith(b'\x89PNG'):  # PNGæ–‡ä»¶å¤´
                            logger.info("ä¸‹è½½çš„æ˜¯æœ‰æ•ˆçš„PNGå›¾ç‰‡")
                        else:
                            logger.error(f"æœªçŸ¥çš„æ–‡ä»¶æ ¼å¼ï¼Œæ–‡ä»¶å¤´: {header.hex()}")
            return False
            
    except Exception as e:
        logger.error(f"curlä¸‹è½½å¼‚å¸¸: {str(e)}")
        return False

@router.get("/curl-proxy/video")
async def curl_proxy_video(
    url: str,
    force_download: bool = False
):
    """
    ä½¿ç”¨curlä»£ç†è§†é¢‘
    
    Args:
        url: è§†é¢‘URL
        force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
    """
    try:
        # éªŒè¯URL
        if not url or not url.startswith(('http://', 'https://')):
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„è§†é¢‘URL")
        
        video_path = get_video_path(url)
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰æ–‡ä»¶
        if os.path.exists(video_path) and not force_download:
            logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜è§†é¢‘: {video_path}")
            return FileResponse(
                video_path,
                media_type='video/mp4',
                headers={
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                    'Access-Control-Allow-Headers': '*',
                    'Cache-Control': 'public, max-age=86400',
                }
            )
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä¸‹è½½
        loop = asyncio.get_event_loop()
        success = await loop.run_in_executor(
            executor, 
            download_with_curl, 
            url, 
            video_path, 
            True
        )
        
        if success:
            return FileResponse(
                video_path,
                media_type='video/mp4',
                headers={
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                    'Access-Control-Allow-Headers': '*',
                    'Cache-Control': 'public, max-age=86400',
                }
            )
        else:
            raise HTTPException(status_code=500, detail="è§†é¢‘ä¸‹è½½å¤±è´¥")
        
    except Exception as e:
        logger.error(f"Curlè§†é¢‘ä»£ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Curlè§†é¢‘ä»£ç†å¤±è´¥: {str(e)}")

@router.get("/curl-proxy/thumbnail")
async def curl_proxy_thumbnail(
    url: str,
    force_download: bool = False
):
    """
    ä½¿ç”¨curlä»£ç†ç¼©ç•¥å›¾
    """
    try:
        # éªŒè¯URL
        if not url or not url.startswith(('http://', 'https://')):
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ç¼©ç•¥å›¾URL")
        
        # ç”Ÿæˆç¼©ç•¥å›¾æ–‡ä»¶å
        url_hash = hashlib.md5(url.encode()).hexdigest()
        thumbnail_path = os.path.join(VIDEO_CACHE_DIR, f"{url_hash}.jpg")
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰æ–‡ä»¶
        if os.path.exists(thumbnail_path) and not force_download:
            logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜ç¼©ç•¥å›¾: {thumbnail_path}")
            return FileResponse(
                thumbnail_path,
                media_type='image/jpeg',
                headers={
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                    'Access-Control-Allow-Headers': '*',
                    'Cache-Control': 'public, max-age=86400',
                }
            )
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä¸‹è½½
        loop = asyncio.get_event_loop()
        success = await loop.run_in_executor(
            executor, 
            download_with_curl, 
            url, 
            thumbnail_path, 
            False
        )
        
        if success:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°åˆç†
            if os.path.exists(thumbnail_path) and os.path.getsize(thumbnail_path) > 100:
                logger.info(f"ç¼©ç•¥å›¾ä»£ç†æˆåŠŸ: {thumbnail_path}, å¤§å°: {os.path.getsize(thumbnail_path)} å­—èŠ‚")
                return FileResponse(
                    thumbnail_path,
                    media_type='image/jpeg',
                    headers={
                        'Access-Control-Allow-Origin': '*',
                        'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                        'Access-Control-Allow-Headers': '*',
                        'Cache-Control': 'public, max-age=86400',
                    }
                )
            else:
                file_size = os.path.getsize(thumbnail_path) if os.path.exists(thumbnail_path) else 0
                logger.error(f"ç¼©ç•¥å›¾æ–‡ä»¶æ— æ•ˆ: {thumbnail_path}, å¤§å°: {file_size} å­—èŠ‚")
                # ğŸ†• æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                error_detail = f"ç¼©ç•¥å›¾æ–‡ä»¶æ— æ•ˆï¼Œå¤§å°: {file_size} å­—èŠ‚"
                if file_size < 100:
                    error_detail += "ï¼Œæ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢"
                raise HTTPException(status_code=500, detail=error_detail)
        else:
            logger.error(f"ç¼©ç•¥å›¾ä¸‹è½½å¤±è´¥: {url}")
            # ğŸ†• æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            raise HTTPException(status_code=500, detail=f"ç¼©ç•¥å›¾ä¸‹è½½å¤±è´¥: {url}")
        
    except Exception as e:
        logger.error(f"Curlç¼©ç•¥å›¾ä»£ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Curlç¼©ç•¥å›¾ä»£ç†å¤±è´¥: {str(e)}")

@router.get("/curl-proxy/status")
async def get_curl_proxy_status():
    """è·å–Curlä»£ç†çŠ¶æ€"""
    try:
        # ç»Ÿè®¡ç¼“å­˜æ–‡ä»¶
        cache_files = os.listdir(VIDEO_CACHE_DIR)
        video_files = [f for f in cache_files if f.endswith('.mp4')]
        image_files = [f for f in cache_files if f.endswith(('.jpg', '.png', '.webp'))]
        
        # è®¡ç®—æ€»å¤§å°
        total_size = 0
        for file in cache_files:
            file_path = os.path.join(VIDEO_CACHE_DIR, file)
            if os.path.isfile(file_path):
                total_size += os.path.getsize(file_path)
        
        return {
            "cache_dir": VIDEO_CACHE_DIR,
            "video_count": len(video_files),
            "image_count": len(image_files),
            "total_files": len(cache_files),
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "status": "ready",
            "method": "curl-command"
        }
        
    except Exception as e:
        logger.error(f"è·å–Curlä»£ç†çŠ¶æ€å¤±è´¥: {str(e)}")
        return {
            "status": "error",
            "error": str(e)
        }

@router.delete("/curl-proxy/clear")
async def clear_curl_proxy_cache():
    """æ¸…ç†Curlä»£ç†ç¼“å­˜"""
    try:
        cache_files = os.listdir(VIDEO_CACHE_DIR)
        deleted_count = 0
        
        for file in cache_files:
            file_path = os.path.join(VIDEO_CACHE_DIR, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
                deleted_count += 1
        
        return {
            "message": "Curlä»£ç†ç¼“å­˜æ¸…ç†å®Œæˆ",
            "deleted_count": deleted_count
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†Curlä»£ç†ç¼“å­˜å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†Curlä»£ç†ç¼“å­˜å¤±è´¥: {str(e)}") 