"""
å¤šå¹³å°çˆ¬å–æ ¸å¿ƒæ¨¡å—
æ”¯æŒåŒæ—¶çˆ¬å–å¤šä¸ªå¹³å°ï¼Œç»Ÿä¸€æ•°æ®æ ¼å¼å­˜å‚¨
"""

import asyncio
import uuid
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum
from fastapi import APIRouter, BackgroundTasks, HTTPException
from pydantic import BaseModel, Field
from tools import utils
from var import media_crawler_db_var

# å¯¼å…¥æ•°æ®æ¨¡å‹
from models.content_models import (
    MultiPlatformCrawlerRequest, MultiPlatformTaskStatusResponse,
    UnifiedResultResponse
)

router = APIRouter()

# å…¨å±€å¤šå¹³å°ä»»åŠ¡çŠ¶æ€å­˜å‚¨
multi_platform_task_status = {}

class AccountStrategy(str, Enum):
    """è´¦å·ç­–ç•¥æšä¸¾"""
    RANDOM = "random"           # éšæœºé€‰æ‹©
    ROUND_ROBIN = "round_robin" # è½®è¯¢é€‰æ‹©
    PRIORITY = "priority"        # ä¼˜å…ˆçº§é€‰æ‹©
    SMART = "smart"             # æ™ºèƒ½é€‰æ‹©ï¼ˆæ ¹æ®ç™»å½•çŠ¶æ€ã€æˆåŠŸç‡ç­‰ï¼‰
    SINGLE = "single"           # å•è´¦å·ä½¿ç”¨

class MultiPlatformCrawlerFactory:
    """å¤šå¹³å°çˆ¬è™«å·¥å‚ç±»"""
    
    # æ”¯æŒçš„å¹³å°
    SUPPORTED_PLATFORMS = ["xhs", "dy", "ks", "bili"]
    
    @staticmethod
    def _get_crawler_class(platform: str):
        """å»¶è¿Ÿå¯¼å…¥çˆ¬è™«ç±»"""
        if platform == "xhs":
            from media_platform.xhs import XiaoHongShuCrawler
            return XiaoHongShuCrawler
        elif platform == "dy":
            from media_platform.douyin import DouYinCrawler
            return DouYinCrawler
        elif platform == "ks":
            from media_platform.kuaishou import KuaishouCrawler
            return KuaishouCrawler
        elif platform == "bili":
            from media_platform.bilibili import BilibiliCrawler
            return BilibiliCrawler
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¹³å°: {platform}")

    @staticmethod
    def create_crawler(platform: str, task_id: str = None):
        """åˆ›å»ºçˆ¬è™«å®ä¾‹"""
        crawler_class = MultiPlatformCrawlerFactory._get_crawler_class(platform)
        return crawler_class(task_id=task_id)

async def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        from config.env_config_loader import config_loader
        from async_db import AsyncMysqlDB
        import aiomysql
        
        db_config = config_loader.get_database_config()
        
        pool = await aiomysql.create_pool(
            host=db_config['host'],
            port=db_config['port'],
            user=db_config['username'],
            password=db_config['password'],
            db=db_config['database'],
            autocommit=True,
            minsize=1,
            maxsize=10,
        )
        
        async_db_obj = AsyncMysqlDB(pool)
        return async_db_obj
        
    except Exception as e:
        utils.logger.error(f"è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

async def create_multi_platform_task_record(task_id: str, request: MultiPlatformCrawlerRequest) -> None:
    """åˆ›å»ºå¤šå¹³å°ä»»åŠ¡è®°å½•åˆ°æ•°æ®åº“"""
    try:
        async_db_obj = await get_db_connection()
        if not async_db_obj:
            utils.logger.error("[MULTI_TASK_RECORD] æ— æ³•è·å–æ•°æ®åº“è¿æ¥")
            return
        
        # æ„å»ºä»»åŠ¡å‚æ•°JSON
        task_params = {
            "platforms": request.platforms,
            "keywords": request.keywords,
            "max_count_per_platform": request.max_count_per_platform,
            "enable_comments": request.enable_comments,
            "enable_images": request.enable_images,
            "save_format": request.save_format,
            "use_proxy": request.use_proxy,
            "proxy_strategy": request.proxy_strategy,
            "account_strategy": request.account_strategy if hasattr(request, 'account_strategy') else "smart",
            "execution_mode": request.execution_mode if hasattr(request, 'execution_mode') else "parallel"
        }
        
        # ä½¿ç”¨å­—å…¸æ–¹å¼æ„å»ºæ•°æ®
        task_data = {
            'id': task_id,
            'platform': ','.join(request.platforms),  # å¤šå¹³å°ç”¨é€—å·åˆ†éš”
            'task_type': 'multi_platform',
            'crawler_type': 'search',  # å¤šå¹³å°é»˜è®¤ä¸ºæœç´¢æ¨¡å¼
            'creator_ref_ids': None,
            'keywords': request.keywords,
            'status': 'pending',
            'progress': 0.0,
            'result_count': 0,
            'error_message': None,
            'user_id': None,
            'params': json.dumps(task_params),
            'priority': 0,
            'is_favorite': False,
            'deleted': False,
            'is_pinned': False,
            'ip_address': None,
            'user_security_id': None,
            'user_signature': None,
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'started_at': None,
            'completed_at': None
        }
        
        await async_db_obj.item_to_table('crawler_tasks', task_data)
        utils.logger.info(f"[MULTI_TASK_RECORD] å¤šå¹³å°ä»»åŠ¡è®°å½•åˆ›å»ºæˆåŠŸ: {task_id}")
        
    except Exception as e:
        utils.logger.error(f"[MULTI_TASK_RECORD] åˆ›å»ºå¤šå¹³å°ä»»åŠ¡è®°å½•å¤±è´¥: {e}")
        raise

async def update_multi_platform_task_progress(task_id: str, progress: float, status: str = None, 
                                           platform_results: Dict[str, int] = None):
    """æ›´æ–°å¤šå¹³å°ä»»åŠ¡è¿›åº¦"""
    try:
        async_db_obj = await get_db_connection()
        if not async_db_obj:
            utils.logger.error("[MULTI_TASK_PROGRESS] æ— æ³•è·å–æ•°æ®åº“è¿æ¥")
            return
        
        # æ„å»ºæ›´æ–°æ•°æ®å­—å…¸
        update_data = {
            'progress': progress,
            'updated_at': datetime.now()
        }
        
        if status:
            update_data['status'] = status
        
        if platform_results:
            total_results = sum(platform_results.values())
            update_data['result_count'] = total_results
        
        await async_db_obj.update_table('crawler_tasks', update_data, 'id', task_id)
        
        utils.logger.info(f"[MULTI_TASK_PROGRESS] å¤šå¹³å°ä»»åŠ¡è¿›åº¦æ›´æ–°: {task_id}, è¿›åº¦: {progress}, çŠ¶æ€: {status}")
        
    except Exception as e:
        utils.logger.error(f"[MULTI_TASK_PROGRESS] æ›´æ–°å¤šå¹³å°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")

async def log_multi_platform_task_step(task_id: str, platform: str, step: str, message: str, 
                                     log_level: str = "INFO", progress: int = None):
    """è®°å½•å¤šå¹³å°ä»»åŠ¡æ­¥éª¤æ—¥å¿—"""
    try:
        async_db_obj = await get_db_connection()
        if not async_db_obj:
            utils.logger.error("[MULTI_TASK_LOG] æ— æ³•è·å–æ•°æ®åº“è¿æ¥")
            return
        
        # æ„å»ºæ—¥å¿—æ•°æ®å­—å…¸
        log_data = {
            'task_id': task_id,
            'platform': platform,
            'account_id': None,
            'log_level': log_level,
            'message': message,
            'step': step,
            'progress': progress or 0,
            'created_at': datetime.now()
        }
        
        await async_db_obj.item_to_table('crawler_task_logs', log_data)
        utils.logger.info(f"[MULTI_TASK_LOG] {task_id} - {platform} - {step}: {message}")
        
    except Exception as e:
        utils.logger.error(f"[MULTI_TASK_LOG] è®°å½•å¤šå¹³å°ä»»åŠ¡æ—¥å¿—å¤±è´¥: {e}")

async def get_platform_accounts(platform: str, account_strategy: str = "smart") -> List[Dict]:
    """æ ¹æ®ç­–ç•¥è·å–å¹³å°è´¦å·åˆ—è¡¨"""
    try:
        async_db_obj = await get_db_connection()
        if not async_db_obj:
            return []
        
        # ğŸ†• ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„è¡¨ç»“æ„ï¼Œå‚è€ƒå•å¹³å°çˆ¬å–çš„è´¦å·ç®¡ç†é€»è¾‘
        # è·å–è¯¥å¹³å°çš„æ‰€æœ‰å¯ç”¨è´¦å·ï¼ˆä»social_accountsè¡¨ï¼‰
        query = """
            SELECT sa.id, sa.account_name, sa.username, sa.platform, sa.login_method,
                   lt.is_valid, lt.expires_at, lt.last_used_at, lt.created_at as token_created_at
            FROM social_accounts sa
            LEFT JOIN login_tokens lt ON sa.id = lt.account_id AND sa.platform = lt.platform
            WHERE sa.platform = %s
            ORDER BY 
                CASE 
                    WHEN lt.is_valid = 1 AND lt.expires_at > NOW() THEN 1
                    ELSE 2
                END,
                lt.created_at DESC,
                sa.created_at DESC
        """
        
        accounts = await async_db_obj.query(query, platform)
        
        if not accounts:
            utils.logger.warning(f"å¹³å° {platform} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¦å·")
            return []
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„è´¦å·ï¼ˆæœ‰æœ‰æ•ˆtokençš„è´¦å·ï¼‰
        valid_accounts = []
        for account in accounts:
            if account.get('is_valid') == 1 and account.get('expires_at'):
                # æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ
                from datetime import datetime
                expires_at = account['expires_at']
                if isinstance(expires_at, str):
                    from datetime import datetime
                    expires_at = datetime.fromisoformat(expires_at.replace('Z', '+00:00'))
                
                if expires_at > datetime.now():
                    valid_accounts.append(account)
        
        if not valid_accounts:
            utils.logger.warning(f"å¹³å° {platform} æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç™»å½•è´¦å·")
            return []
        
        utils.logger.info(f"å¹³å° {platform} æ‰¾åˆ° {len(valid_accounts)} ä¸ªæœ‰æ•ˆè´¦å·")
        
        # æ ¹æ®ç­–ç•¥é€‰æ‹©è´¦å·
        if account_strategy == "random":
            import random
            selected = random.sample(valid_accounts, min(len(valid_accounts), 3))
            utils.logger.info(f"éšæœºé€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
        elif account_strategy == "round_robin":
            # è½®è¯¢é€‰æ‹©ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œé€‰æ‹©å‰å‡ ä¸ª
            selected = valid_accounts[:min(len(valid_accounts), 2)]
            utils.logger.info(f"è½®è¯¢é€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
        elif account_strategy == "priority":
            # ä¼˜å…ˆçº§é€‰æ‹©ï¼šæœ‰æ•ˆtoken > æœ€è¿‘ä½¿ç”¨
            selected = valid_accounts[:min(len(valid_accounts), 2)]
            utils.logger.info(f"ä¼˜å…ˆçº§é€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
        elif account_strategy == "smart":
            # æ™ºèƒ½é€‰æ‹©ï¼šç»¼åˆè€ƒè™‘tokenæœ‰æ•ˆæ€§ã€ä½¿ç”¨é¢‘ç‡
            # æŒ‰tokenåˆ›å»ºæ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
            smart_accounts = sorted(valid_accounts, 
                                 key=lambda x: x.get('token_created_at', datetime.min), 
                                 reverse=True)
            selected = smart_accounts[:min(len(smart_accounts), 2)]
            utils.logger.info(f"æ™ºèƒ½é€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
        elif account_strategy == "single":
            # å•è´¦å·ä½¿ç”¨
            selected = valid_accounts[:1]
            utils.logger.info(f"å•è´¦å·é€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
        else:
            # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
            selected = valid_accounts[:1]
            utils.logger.info(f"é»˜è®¤é€‰æ‹© {len(selected)} ä¸ªè´¦å·")
            return selected
            
    except Exception as e:
        utils.logger.error(f"è·å–å¹³å° {platform} è´¦å·å¤±è´¥: {e}")
        return []

async def run_single_platform_crawler(task_id: str, platform: str, request: MultiPlatformCrawlerRequest, 
                                    account_strategy: str = "smart", execution_mode: str = "parallel"):
    """è¿è¡Œå•ä¸ªå¹³å°çš„çˆ¬è™«ä»»åŠ¡"""
    try:
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸš€ å¼€å§‹æ‰§è¡Œå¹³å° {platform} çˆ¬å–ä»»åŠ¡")
        
        # è·å–å¹³å°è´¦å·
        accounts = await get_platform_accounts(platform, account_strategy)
        if not accounts:
            raise Exception(f"å¹³å° {platform} æ²¡æœ‰å¯ç”¨è´¦å·")
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªè´¦å·
        selected_account = accounts[0]
        account_id = selected_account['id']
        
        await log_multi_platform_task_step(task_id, platform, "account_selected", 
                                         f"é€‰æ‹©è´¦å·: {selected_account.get('account_name', 'æœªçŸ¥')} (ID: {account_id})")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = MultiPlatformCrawlerFactory.create_crawler(platform, task_id=task_id)
        
        # è®¾ç½®çˆ¬è™«é…ç½®
        import config
        config.PLATFORM = platform
        config.ENABLE_GET_COMMENTS = request.enable_comments
        config.SAVE_DATA_OPTION = "db"  # å¤šå¹³å°å›ºå®šä½¿ç”¨æ•°æ®åº“å­˜å‚¨
        
        # å¼€å§‹çˆ¬å–
        await log_multi_platform_task_step(task_id, platform, "crawling_start", "å¼€å§‹æ‰§è¡Œçˆ¬å–")
        
        results = await crawler.search_by_keywords(
            keywords=request.keywords,
            max_count=request.max_count_per_platform,
            account_id=account_id,
            session_id=None,
            login_type="qrcode",
            get_comments=request.enable_comments,
            save_data_option="db",
            use_proxy=request.use_proxy,
            proxy_strategy=request.proxy_strategy
        )
        
        result_count = len(results) if results else 0
        await log_multi_platform_task_step(task_id, platform, "crawling_completed", 
                                         f"çˆ¬å–å®Œæˆï¼Œå…±è·å– {result_count} æ¡æ•°æ®")
        
        # å®‰å…¨å…³é—­çˆ¬è™«èµ„æº
        try:
            if hasattr(crawler, 'close'):
                await crawler.close()
        except Exception as e:
            utils.logger.warning(f"[MULTI_TASK_{task_id}] å…³é—­çˆ¬è™«èµ„æºæ—¶å‡ºç°è­¦å‘Š: {e}")
        
        return result_count
        
    except Exception as e:
        utils.logger.error(f"[MULTI_TASK_{task_id}] âŒ å¹³å° {platform} çˆ¬å–å¤±è´¥: {e}")
        await log_multi_platform_task_step(task_id, platform, "crawling_failed", f"çˆ¬å–å¤±è´¥: {str(e)}", "ERROR")
        raise

async def run_multi_platform_crawler_task(task_id: str, request: MultiPlatformCrawlerRequest):
    """åå°è¿è¡Œå¤šå¹³å°çˆ¬è™«ä»»åŠ¡"""
    try:
        utils.logger.info("â–ˆ" * 100)
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸš€ å¼€å§‹æ‰§è¡Œå¤šå¹³å°çˆ¬è™«ä»»åŠ¡")
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ“ è¯·æ±‚å‚æ•°è¯¦æƒ…:")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ platforms: {request.platforms}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ keywords: {request.keywords}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ max_count_per_platform: {request.max_count_per_platform}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ enable_comments: {request.enable_comments}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ enable_images: {request.enable_images}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ save_format: {request.save_format}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ use_proxy: {request.use_proxy}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ proxy_strategy: {request.proxy_strategy}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ account_strategy: {getattr(request, 'account_strategy', 'smart')}")
        utils.logger.info(f"[MULTI_TASK_{task_id}]   â””â”€ execution_mode: {getattr(request, 'execution_mode', 'parallel')}")
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ“Š åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        try:
            from db import init_mediacrawler_db
            await init_mediacrawler_db()
            utils.logger.info(f"[MULTI_TASK_{task_id}] âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            utils.logger.error(f"[MULTI_TASK_{task_id}] âŒ æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ“ åˆ›å»ºå¤šå¹³å°ä»»åŠ¡è®°å½•...")
        await create_multi_platform_task_record(task_id, request)
        utils.logger.info(f"[MULTI_TASK_{task_id}] âœ… å¤šå¹³å°ä»»åŠ¡è®°å½•åˆ›å»ºæˆåŠŸ")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        multi_platform_task_status[task_id]["status"] = "running"
        multi_platform_task_status[task_id]["started_at"] = datetime.now().isoformat()
        await update_multi_platform_task_progress(task_id, 0.0, "running")
        await log_multi_platform_task_step(task_id, "multi", "task_start", "å¤šå¹³å°ä»»åŠ¡å¼€å§‹æ‰§è¡Œ")
        
        # è·å–æ‰§è¡Œæ¨¡å¼å’Œè´¦å·ç­–ç•¥
        execution_mode = getattr(request, 'execution_mode', 'parallel')
        account_strategy = getattr(request, 'account_strategy', 'smart')
        
        # æ‰§è¡Œçˆ¬å–ä»»åŠ¡
        platform_results = {}
        platform_errors = {}
        
        if execution_mode == "parallel":
            # å¹¶è¡Œæ‰§è¡Œ
            utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ”„ å¹¶è¡Œæ‰§è¡Œæ¨¡å¼")
            await log_multi_platform_task_step(task_id, "multi", "execution_mode", "å¹¶è¡Œæ‰§è¡Œæ¨¡å¼")
            
            # åˆ›å»ºæ‰€æœ‰å¹³å°çš„çˆ¬å–ä»»åŠ¡
            tasks = []
            for platform in request.platforms:
                task = run_single_platform_crawler(task_id, platform, request, account_strategy, execution_mode)
                tasks.append((platform, task))
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*[task for _, task in tasks], return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for i, (platform, _) in enumerate(tasks):
                if isinstance(results[i], Exception):
                    platform_errors[platform] = str(results[i])
                    platform_results[platform] = 0
                else:
                    platform_results[platform] = results[i]
                    
        else:
            # é¡ºåºæ‰§è¡Œ
            utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ”„ é¡ºåºæ‰§è¡Œæ¨¡å¼")
            await log_multi_platform_task_step(task_id, "multi", "execution_mode", "é¡ºåºæ‰§è¡Œæ¨¡å¼")
            
            for i, platform in enumerate(request.platforms):
                try:
                    progress = (i / len(request.platforms)) * 100
                    await update_multi_platform_task_progress(task_id, progress)
                    await log_multi_platform_task_step(task_id, "multi", "platform_start", f"å¼€å§‹æ‰§è¡Œå¹³å° {platform}")
                    
                    result_count = await run_single_platform_crawler(task_id, platform, request, account_strategy, execution_mode)
                    platform_results[platform] = result_count
                    
                    await log_multi_platform_task_step(task_id, "multi", "platform_completed", f"å¹³å° {platform} æ‰§è¡Œå®Œæˆï¼Œè·å– {result_count} æ¡æ•°æ®")
                    
                except Exception as e:
                    platform_errors[platform] = str(e)
                    platform_results[platform] = 0
                    await log_multi_platform_task_step(task_id, "multi", "platform_failed", f"å¹³å° {platform} æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        
        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        total_results = sum(platform_results.values())
        success_platforms = len([p for p in request.platforms if p not in platform_errors])
        
        if platform_errors:
            # ğŸ†• ä¿®å¤ï¼šç¼©çŸ­çŠ¶æ€å€¼ä»¥ç¬¦åˆæ•°æ®åº“å­—æ®µé•¿åº¦é™åˆ¶
            status = "completed_with_errors" if len("completed_with_errors") <= 20 else "completed_errors"
            message = f"éƒ¨åˆ†å¹³å°æ‰§è¡Œå¤±è´¥ï¼ŒæˆåŠŸ: {success_platforms}/{len(request.platforms)} ä¸ªå¹³å°"
        else:
            status = "completed"
            message = f"æ‰€æœ‰å¹³å°æ‰§è¡ŒæˆåŠŸï¼Œå…±è·å– {total_results} æ¡æ•°æ®"
        
        multi_platform_task_status[task_id].update({
            "status": status,
            "results": platform_results,
            "errors": platform_errors,
            "completed_at": datetime.now().isoformat()
        })
        
        await update_multi_platform_task_progress(task_id, 100.0, status, platform_results)
        await log_multi_platform_task_step(task_id, "multi", "task_completed", message)
        
        utils.logger.info(f"[MULTI_TASK_{task_id}] âœ… å¤šå¹³å°çˆ¬å–ä»»åŠ¡å®Œæˆ")
        utils.logger.info(f"[MULTI_TASK_{task_id}] ğŸ“Š ç»“æœç»Ÿè®¡:")
        for platform, count in platform_results.items():
            utils.logger.info(f"[MULTI_TASK_{task_id}]   â”œâ”€ {platform}: {count} æ¡")
        if platform_errors:
            utils.logger.info(f"[MULTI_TASK_{task_id}]   â””â”€ é”™è¯¯: {platform_errors}")
        utils.logger.info("â–ˆ" * 100)
        
    except Exception as e:
        utils.logger.error("â–ˆ" * 100)
        utils.logger.error(f"[MULTI_TASK_{task_id}] âŒ å¤šå¹³å°çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
        utils.logger.error(f"[MULTI_TASK_{task_id}] ğŸ› é”™è¯¯è¯¦æƒ…: {e}")
        utils.logger.error(f"[MULTI_TASK_{task_id}] ğŸ“ é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        utils.logger.error(f"[MULTI_TASK_{task_id}] ğŸ“Š é”™è¯¯å †æ ˆ:")
        utils.logger.error(f"[MULTI_TASK_{task_id}] {traceback.format_exc()}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        multi_platform_task_status[task_id]["status"] = "failed"
        multi_platform_task_status[task_id]["error"] = str(e)
        multi_platform_task_status[task_id]["completed_at"] = datetime.now().isoformat()
        await update_multi_platform_task_progress(task_id, 0.0, "failed")
        await log_multi_platform_task_step(task_id, "multi", "task_failed", f"å¤šå¹³å°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        utils.logger.error("â–ˆ" * 100)

@router.post("/multi-platform/start", response_model=MultiPlatformTaskStatusResponse)
async def start_multi_platform_crawler(request: MultiPlatformCrawlerRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨å¤šå¹³å°çˆ¬è™«ä»»åŠ¡"""
    try:
        utils.logger.info("=" * 100)
        utils.logger.info("[MULTI_CRAWLER_START] æ”¶åˆ°å¤šå¹³å°çˆ¬è™«ä»»åŠ¡å¯åŠ¨è¯·æ±‚")
        utils.logger.info(f"[MULTI_CRAWLER_START] å¹³å°: {request.platforms}")
        utils.logger.info(f"[MULTI_CRAWLER_START] å…³é”®è¯: {request.keywords}")
        utils.logger.info(f"[MULTI_CRAWLER_START] æ¯å¹³å°æœ€å¤§æ•°é‡: {request.max_count_per_platform}")
        
        # å‚æ•°éªŒè¯
        if not request.platforms:
            raise HTTPException(status_code=400, detail="è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå¹³å°")
        
        if not request.keywords.strip():
            raise HTTPException(status_code=400, detail="è¯·è¾“å…¥æœç´¢å…³é”®è¯")
        
        # æ£€æŸ¥å¹³å°æ”¯æŒæƒ…å†µ
        unsupported_platforms = [p for p in request.platforms if p not in MultiPlatformCrawlerFactory.SUPPORTED_PLATFORMS]
        if unsupported_platforms:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„å¹³å°: {', '.join(unsupported_platforms)}")
        
        # æ£€æŸ¥å„å¹³å°ç™»å½•çŠ¶æ€
        utils.logger.info("[MULTI_CRAWLER_START] æ£€æŸ¥å„å¹³å°ç™»å½•çŠ¶æ€...")
        login_issues = []
        
        for platform in request.platforms:
            try:
                import httpx
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        "http://localhost:8100/api/v1/login/check",
                        json={"platform": platform},
                        timeout=10.0
                    )
                    login_result = response.json()
                    
                    if login_result["code"] != 200:
                        login_issues.append(f"{platform}: {login_result.get('message', 'unknown')}")
                        
            except Exception as e:
                login_issues.append(f"{platform}: æ£€æŸ¥å¤±è´¥ - {str(e)}")
        
        if login_issues:
            utils.logger.warning(f"[MULTI_CRAWLER_START] éƒ¨åˆ†å¹³å°ç™»å½•çŠ¶æ€å¼‚å¸¸: {login_issues}")
            # ç»§ç»­æ‰§è¡Œï¼Œä½†è®°å½•è­¦å‘Š
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        utils.logger.info(f"[MULTI_CRAWLER_START] ç”Ÿæˆä»»åŠ¡ID: {task_id}")
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        multi_platform_task_status[task_id] = {
            "task_id": task_id,
            "status": "pending",
            "platforms": request.platforms,
            "keywords": request.keywords,
            "progress": {
                "total": len(request.platforms),
                "completed": 0,
                "failed": 0,
                "pending": len(request.platforms)
            },
            "results": {},
            "errors": {},
            "created_at": datetime.now().isoformat(),
            "started_at": None,
            "completed_at": None
        }
        utils.logger.info("[MULTI_CRAWLER_START] å¤šå¹³å°ä»»åŠ¡çŠ¶æ€å·²åˆå§‹åŒ–")
        
        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(run_multi_platform_crawler_task, task_id, request)
        utils.logger.info("[MULTI_CRAWLER_START] åå°ä»»åŠ¡å·²æ·»åŠ ")
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "task_id": task_id,
            "status": "pending",
            "platforms": request.platforms,
            "keywords": request.keywords,
            "progress": {
                "total": len(request.platforms),
                "completed": 0,
                "failed": 0,
                "pending": len(request.platforms)
            },
            "results": {},
            "errors": {},
            "created_at": datetime.now().isoformat(),
            "started_at": None,
            "completed_at": None
        }
        utils.logger.info(f"[MULTI_CRAWLER_START] å“åº”æ•°æ®: {response_data}")
        utils.logger.info("=" * 100)
        
        return MultiPlatformTaskStatusResponse(**response_data)
        
    except Exception as e:
        utils.logger.error(f"[MULTI_CRAWLER_START] å¯åŠ¨å¤šå¹³å°çˆ¬è™«ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å¤šå¹³å°çˆ¬è™«ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.get("/multi-platform/status/{task_id}", response_model=MultiPlatformTaskStatusResponse)
async def get_multi_platform_task_status(task_id: str):
    """è·å–å¤šå¹³å°ä»»åŠ¡çŠ¶æ€"""
    if task_id not in multi_platform_task_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return MultiPlatformTaskStatusResponse(**multi_platform_task_status[task_id])

@router.get("/multi-platform/tasks")
async def list_multi_platform_tasks():
    """è·å–æ‰€æœ‰å¤šå¹³å°ä»»åŠ¡åˆ—è¡¨"""
    return {
        "tasks": list(multi_platform_task_status.values()),
        "total": len(multi_platform_task_status)
    }

@router.delete("/multi-platform/tasks/{task_id}")
async def delete_multi_platform_task(task_id: str):
    """åˆ é™¤å¤šå¹³å°ä»»åŠ¡"""
    if task_id not in multi_platform_task_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    del multi_platform_task_status[task_id]
    return {"message": "å¤šå¹³å°ä»»åŠ¡å·²åˆ é™¤"}

@router.get("/multi-platform/info")
async def get_multi_platform_info():
    """è·å–å¤šå¹³å°åŠŸèƒ½ä¿¡æ¯"""
    return {
        "supported_platforms": MultiPlatformCrawlerFactory.SUPPORTED_PLATFORMS,
        "account_strategies": [strategy.value for strategy in AccountStrategy],
        "execution_modes": ["parallel", "sequential"],
        "save_formats": ["db"],  # å¤šå¹³å°å›ºå®šä½¿ç”¨æ•°æ®åº“å­˜å‚¨
        "features": {
            "concurrent_crawling": True,
            "unified_data_format": True,
            "account_management": True,
            "progress_tracking": True,
            "error_handling": True
        }
    } 