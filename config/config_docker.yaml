# Docker容器环境配置文件
# 使用方式: ENV=docker python main.py

# ==================== 日志配置 ====================
logging:
  # 日志级别
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  
  # 日志文件配置
  file_enabled: true
  file_path: "./logs"
  file_name_pattern: "mediacrawler_{date}.log"
  file_encoding: "utf-8"
  
  # 日志保留策略
  retention_days: 15  # 保留15天，半个月后自动删除
  max_file_size_mb: 100  # 单个日志文件最大100MB
  max_files_count: 10  # 最多保留10个日志文件
  
  # 日志格式
  format: "%(asctime)s %(name)s %(levelname)s (%(filename)s:%(lineno)d) - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
  
  # 输出配置
  console_enabled: true
  file_enabled: true
  
  # 特殊日志配置
  crawler_log_level: "INFO"  # 爬虫相关日志级别
  api_log_level: "INFO"      # API相关日志级别
  db_log_level: "WARNING"    # 数据库相关日志级别

# ==================== 代理配置 ====================
proxy:
  # 代理提供商配置
  provider_name: "qingguo"  # 容器环境推荐使用青果代理
  enabled: false  # 容器环境默认禁用代理，可通过环境变量启用
  pool_count: 10
  validate_ip: true
  
  # 青果代理配置（从环境变量读取）
  qingguo_key: "${QINGGUO_KEY:-}"
  qingguo_pwd: "${QINGGUO_PWD:-}"
  
  # 快代理配置（从环境变量读取）
  kuaidaili_secret_id: "${KUAIDAILI_SECRET_ID:-}"
  kuaidaili_signature: "${KUAIDAILI_SIGNATURE:-}"
  kuaidaili_user_name: "${KUAIDAILI_USERNAME:-}"
  kuaidaili_user_pwd: "${KUAIDAILI_PASSWORD:-}"
  
  # 极速HTTP代理配置（从环境变量读取）
  jisu_http_key: "${JISU_HTTP_KEY:-}"

# ==================== 爬虫配置 ====================
crawler:
  platform: "xhs"
  keywords: "编程副业,编程兼职"
  login_type: "qrcode"
  crawler_type: "search"
  max_notes_count: 300  # 容器环境适中设置
  enable_comments: true
  enable_sub_comments: false
  enable_images: false
  save_data_option: "db"  # 容器环境推荐使用数据库
  headless: false  # 远程桌面登录需要可见界面
  max_sleep_sec: 2
  max_concurrency: 2  # 容器环境适度并发

# ==================== 数据库配置 ====================
database:
  # 数据库配置（从环境变量读取）
  host: "${DB_HOST:-192.168.31.231}"
  port: ${DB_PORT:-3306}
  username: "${DB_USER:-aiuser}"
  password: "${DB_PASSWORD:-edcghj98578}"
  database: "${DB_NAME:-mediacrawler}"
  charset: "utf8mb4"

# ==================== Redis配置 ====================
redis:
  host: "localhost"
  port: 6379
  db: 0
  password: ""
  connection_pool_size: 10
  max_connections: 100
  socket_timeout: 5
  socket_connect_timeout: 5
  socket_keepalive: true
  socket_keepalive_options: {}
  health_check_interval: 30
  retry_on_timeout: true
  
  # 任务结果缓存配置
  task_result_ttl: 604800  # 7天过期时间
  task_result_key_prefix: "mediacrawler:task:"
  
  # 会话缓存配置
  session_ttl: 3600  # 1小时过期时间
  session_key_prefix: "mediacrawler:session:"

# ==================== 应用配置 ====================
app:
  debug: false
  log_level: "INFO"
  data_dir: "/app/data"  # 容器内路径
  user_data_dir: "/app/data/%s_user_data_dir"

# ==================== 远程桌面配置 ====================
remote_desktop:
  # 远程桌面配置（容器环境）
  enabled: ${REMOTE_DESKTOP_ENABLED:-true}
  vnc_url: "${VNC_URL:-http://localhost:6080/vnc.html}"
  vnc_host: "${VNC_HOST:-localhost}"
  vnc_port: ${VNC_PORT:-6080}
  vnc_password: "${VNC_PASSWORD:-mediacrawler123}"
  display_number: ${DISPLAY_NUMBER:-1}
  connection_timeout: 10  # 容器环境增加超时时间
  max_wait_time: 1800  # 30分钟
  check_interval: 3    # 3秒检查一次

# ==================== 存储配置 ====================
storage:
  # 本地存储配置
  local_base_path: "/app/data"
  small_file_threshold: 10485760  # 10MB
  
  # MinIO配置
  enable_minio: false
  minio_endpoint: "${MINIO_ENDPOINT:-localhost:9000}"
  minio_access_key: "${MINIO_ACCESS_KEY:-minioadmin}"
  minio_secret_key: "${MINIO_SECRET_KEY:-minioadmin}"
  minio_secure: false
  minio_bucket: "mediacrawler-videos"
  
  # 数据库配置
  database_url: "mysql+pymysql://${DB_USER:-aiuser}:${DB_PASSWORD:-edcghj98578}@${DB_HOST:-192.168.31.231}:${DB_PORT:-3306}/${DB_NAME:-mediacrawler}"
  pool_size: 10
  max_overflow: 20
  pool_timeout: 30
  pool_recycle: 3600
  
  # 文件管理配置
  naming_pattern: "{platform}/{date}/{content_id}/{filename}"
  date_format: "%Y/%m/%d"
  supported_formats:
    - "mp4"
    - "avi"
    - "mov"
    - "mkv"
    - "flv" 
    - "webm"
    - "m4v"
    - "3gp"
  
  # 文件大小限制
  max_file_size: 1073741824  # 1GB
  min_file_size: 1024  # 1KB
  
  # 重复文件处理
  duplicate_check: true
  duplicate_strategy: "skip"
  
  # 文件清理策略
  cleanup:
    enabled: false
    retention_days: 30
    cleanup_interval_hours: 24
  
  # 性能优化配置
  max_concurrent_downloads: 3  # 容器环境适度并发
  chunk_size: 8192
  download_timeout: 300
  max_retries: 3
  retry_delay: 5 
  
  # 监控配置
  storage_usage_threshold: 0.8
  file_count_threshold: 10000
  monitor_interval: 3600

# ==================== 服务配置 ====================
server:
  port: 8000
  host: "0.0.0.0"
  debug: false
  enable_cors: true
  static_path: "static"
  max_upload_size: 100

# ==================== 安全配置 ====================
security:
  enable_https: false
  ssl_cert: ""
  ssl_key: ""
  session_secret: "${SESSION_SECRET:-docker-secret-key}"
  session_expire: 86400
  enable_api_auth: false
  api_key: "${API_KEY:-docker-api-key}"

# ==================== 爬虫服务配置 ====================
crawler_service:
  max_processes: 5
  task_timeout: 1800
  result_cache_time: 3600
  enable_monitoring: true
  monitor_interval: 30
  cpu_warning_threshold: 80
  memory_warning_threshold: 85
  disk_warning_threshold: 90

# ==================== 任务管理配置 ====================
task_management:
  max_queue_size: 100
  max_retry_count: 3
  retry_interval: 60
  status_check_interval: 10
  result_retention_days: 30

# ==================== 性能优化配置 ====================
performance:
  enable_cache: true
  cache_size_limit: 100
  enable_compression: true
  enable_async: true
  async_queue_size: 50
  async_timeout: 300

# ==================== 监控配置 ====================
monitoring:
  enable_system_monitor: true
  data_retention_days: 7
  collection_interval: 60
  enable_alerts: true
  alerts:
    cpu_threshold: 80
    memory_threshold: 85
    disk_threshold: 90
    response_time_threshold: 5000

# ==================== 开发环境配置 ====================
development:
  enable_hot_reload: false
  enable_debug_toolbar: false
  enable_detailed_errors: false
  test_mode: false

# ==================== 任务隔离配置 ====================
task_isolation:
  # 任务隔离模式
  isolation_mode: "strict"  # strict: 完全隔离, shared: 共享资源
  
  # 任务并发控制
  max_concurrent_tasks: 15  # Docker环境适中并发数
  max_tasks_per_session: 50  # Docker环境适中任务数
  
  # 资源隔离
  enable_resource_isolation: true
  enable_cross_task_data_access: false
  
  # 认证预留接口
  auth_middleware_enabled: false  # 预留：将来集成用户认证
  auth_token_header: "Authorization"
  auth_session_timeout: 7200  # 2小时

# ==================== 词云配置 ====================
wordcloud:
  enable_get_wordcloud: false
  custom_words:
    "零几": "年份"
    "高频词": "专业术语"
  stop_words_file: "./docs/hit_stopwords.txt"
  font_path: "./docs/STZHONGS.TTF"

# ==================== 定时任务配置 ====================
scheduled_tasks:
  # 登录状态检查任务
  login_status_check:
    enabled: true                    # 是否启用登录状态检查
    interval_hours: 6               # 检查间隔（小时）
    start_time: "02:00"            # 开始时间（24小时制）
    max_concurrent: 5              # 最大并发检查数
    timeout: 30                    # 单个检查超时时间（秒）
    enable_logging: true           # 是否启用详细日志
    
  # 调度器配置
  scheduler:
    max_concurrent_tasks: 3        # 最大并发任务数
    task_timeout_seconds: 3600     # 任务超时时间（秒）
    enable_logging: true           # 是否启用调度器日志

# ==================== 基础配置 ====================
ua: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0'
save_login_state: true 