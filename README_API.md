# MediaCrawler API æœåŠ¡

## æ¦‚è¿°

MediaCrawler API æ˜¯å°†åŸæœ‰çš„å‘½ä»¤è¡Œçˆ¬è™«å·¥å…·åŒ…è£…æˆ HTTP API æœåŠ¡ï¼Œæ–¹ä¾¿é›†æˆåˆ°å…¶ä»–å¹³å°ä¸­ã€‚ç°åœ¨æ”¯æŒå®Œæ•´çš„ä»£ç†ç®¡ç†åŠŸèƒ½å’Œå¤šå¹³å°åŒæ—¶æŠ“å–åŠŸèƒ½ï¼Œæä¾›æ›´å®‰å…¨ã€æ›´ç¨³å®šã€æ›´é«˜æ•ˆçš„çˆ¬å–èƒ½åŠ›ã€‚

## ğŸš€ æ–°å¢åŠŸèƒ½ï¼šå¤šå¹³å°åŒæ—¶æŠ“å–

**æ”¯æŒå¤šå¹³å°ç›¸åŒå…³é”®å­—åŒæ—¶æŠ“å–ï¼** ç°åœ¨æ‚¨å¯ä»¥ï¼š

- âœ… **å¹¶å‘æŠ“å–**ï¼šåŒæ—¶æŠ“å–å¤šä¸ªå¹³å°ï¼Œæé«˜æ•ˆç‡
- âœ… **ç»Ÿä¸€ç»“æœ**ï¼šæ‰€æœ‰å¹³å°æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
- âœ… **çµæ´»é€‰æ‹©**ï¼šæ”¯æŒä»»æ„å¹³å°ç»„åˆï¼ˆ1-7ä¸ªå¹³å°ï¼‰
- âœ… **ä»»åŠ¡ç®¡ç†**ï¼šå®Œæ•´çš„ä»»åŠ¡çŠ¶æ€è·Ÿè¸ªå’Œè¿›åº¦ç›‘æ§
- âœ… **ç»“æœåˆ†æ**ï¼šåŒ…å«ä¸‹è½½é“¾æ¥ã€å…³é”®ä¿¡æ¯å­—æ®µã€æ¥æºå¹³å°

### å¿«é€Ÿå¼€å§‹å¤šå¹³å°æŠ“å–

```bash
# å¯åŠ¨å¤šå¹³å°æŠ“å–ä»»åŠ¡
curl -X POST "http://localhost:8000/api/v1/multi-platform/start" \
  -H "Content-Type: application/json" \
  -d '{
    "platforms": ["xhs", "dy", "ks"],
    "keywords": "ç¾é£Ÿæ¢åº—",
    "max_count_per_platform": 30,
    "enable_images": true,
    "save_format": "json"
  }'

# è·å–ä»»åŠ¡çŠ¶æ€
curl "http://localhost:8000/api/v1/multi-platform/status/{task_id}"

# è·å–ä»»åŠ¡ç»“æœ
curl "http://localhost:8000/api/v1/multi-platform/results/{task_id}?format_type=json"
```

è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·æŸ¥çœ‹ï¼š[APIå¤šå¹³å°æŠ“å–ä½¿ç”¨æŒ‡å—](docs/APIå¤šå¹³å°æŠ“å–ä½¿ç”¨æŒ‡å—.md)

## å¿«é€Ÿå¼€å§‹

### 1. æ„å»ºå¹¶å¯åŠ¨å®¹å™¨

```bash
# ä½¿ç”¨ docker-composeï¼ˆæ¨èï¼‰
docker-compose up -d --build

# æˆ–è€…ä½¿ç”¨ Docker å‘½ä»¤
docker build -f Dockerfile.api -t mediacrawler-api .
docker run -d -p 8000:8000 -v $(pwd)/data:/app/data mediacrawler-api
```

### 2. å¿«é€Ÿæµ‹è¯•

```bash
# è¿è¡Œå¿«é€Ÿæµ‹è¯•è„šæœ¬
chmod +x quick_test.sh
./quick_test.sh

# æˆ–è€…æ‰‹åŠ¨æµ‹è¯•
curl http://localhost:8000/api/v1/health

# æµ‹è¯•å¤šå¹³å°åŠŸèƒ½
python test_api_multi_platform.py
```

### 3. åˆå§‹åŒ–ä»£ç†æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰

```bash
# åˆå§‹åŒ–ä»£ç†ç›¸å…³è¡¨ç»“æ„
python -c "
import asyncio
import db
async def init():
    await db.init_db()
    async_db = db.media_crawler_db_var.get()
    with open('schema/proxy_tables.sql', 'r') as f:
        sql = f.read()
    await async_db.execute(sql)
    await db.close()
asyncio.run(init())
"
```

## API æ¥å£

### åŸºç¡€æ¥å£

#### å¥åº·æ£€æŸ¥
```bash
GET /api/v1/health
```

#### è·å–æ”¯æŒçš„å¹³å°
```bash
GET /api/v1/platforms
```

#### è·å–å¤šå¹³å°åŠŸèƒ½ä¿¡æ¯
```bash
GET /api/v1/multi-platform/info
```

### å¤šå¹³å°æŠ“å–æ¥å£

#### å¯åŠ¨å¤šå¹³å°æŠ“å–ä»»åŠ¡
```bash
POST /api/v1/multi-platform/start
Content-Type: application/json

{
  "platforms": ["xhs", "dy", "ks"],
  "keywords": "ç¾é£Ÿæ¢åº—",
  "max_count_per_platform": 50,
  "enable_comments": false,
  "enable_images": true,
  "save_format": "json",
  "session_ids": {
    "xhs": "session_id_1",
    "dy": "session_id_2"
  }
}
```

#### è·å–å¤šå¹³å°ä»»åŠ¡çŠ¶æ€
```bash
GET /api/v1/multi-platform/status/{task_id}
```

#### è·å–å¤šå¹³å°ä»»åŠ¡ç»“æœ
```bash
GET /api/v1/multi-platform/results/{task_id}?format_type=json
```

#### è·å–å¤šå¹³å°ä»»åŠ¡åˆ—è¡¨
```bash
GET /api/v1/multi-platform/tasks
```

#### å–æ¶ˆå¤šå¹³å°ä»»åŠ¡
```bash
POST /api/v1/multi-platform/cancel/{task_id}
```

### å•å¹³å°çˆ¬è™«ä»»åŠ¡æ¥å£

#### å¯åŠ¨çˆ¬è™«ä»»åŠ¡
```bash
POST /api/v1/crawler/start
Content-Type: application/json

{
  "platform": "xhs",
  "login_type": "qrcode",
  "crawler_type": "search",
  "keywords": "ç¼–ç¨‹",
  "start_page": 1,
  "get_comments": true,
  "get_sub_comments": false,
  "save_data_option": "json",
  "max_notes_count": 100,
  "enable_images": false,
  "use_proxy": true,
  "proxy_strategy": "smart"
}
```

#### è·å–ä»»åŠ¡çŠ¶æ€
```bash
GET /api/v1/crawler/status/{task_id}
```

#### åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
```bash
GET /api/v1/crawler/tasks
```

#### åˆ é™¤ä»»åŠ¡
```bash
DELETE /api/v1/crawler/tasks/{task_id}
```

### ä»£ç†ç®¡ç†æ¥å£

#### è·å–ä»£ç†ç»Ÿè®¡
```bash
GET /api/v1/proxy/stats
```

#### å¿«é€Ÿè·å–ä»£ç†
```bash
GET /api/v1/proxy/quick-get?strategy_type=smart&platform=xhs
```

#### è·å–ä»£ç†åˆ—è¡¨
```bash
GET /api/v1/proxy/list?page=1&page_size=20&status=true&proxy_type=http&country=CN
```

#### æ·»åŠ ä»£ç†
```bash
POST /api/v1/proxy/add
Content-Type: application/json

{
  "proxy_type": "http",
  "ip": "127.0.0.1",
  "port": 8080,
  "username": "user",
  "password": "pass",
  "country": "CN",
  "speed": 100,
  "anonymity": "elite",
  "priority": 10
}
```

#### æ£€æµ‹ä»£ç†
```bash
POST /api/v1/proxy/check/{proxy_id}
```

#### æ‰¹é‡æ£€æµ‹ä»£ç†
```bash
POST /api/v1/proxy/check/batch
Content-Type: application/json

{
  "proxy_ids": [1, 2, 3, 4, 5]
}
```

## å‚æ•°è¯´æ˜

### å¤šå¹³å°æŠ“å–è¯·æ±‚å‚æ•°

| å‚æ•°å | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|------|--------|------|
| **platforms** | **array** | **æ˜¯** | **-** | **å¹³å°åˆ—è¡¨ï¼šxhs, dy, ks, bili, wb, tieba, zhihu** |
| **keywords** | **string** | **æ˜¯** | **-** | **æœç´¢å…³é”®è¯** |
| **max_count_per_platform** | **int** | **å¦** | **50** | **æ¯ä¸ªå¹³å°æœ€å¤§æŠ“å–æ•°é‡** |
| **enable_comments** | **boolean** | **å¦** | **false** | **æ˜¯å¦æŠ“å–è¯„è®º** |
| **enable_images** | **boolean** | **å¦** | **false** | **æ˜¯å¦æŠ“å–å›¾ç‰‡** |
| **save_format** | **string** | **å¦** | **json** | **ä¿å­˜æ ¼å¼ï¼šjson, csv** |
| **session_ids** | **object** | **å¦** | **null** | **å„å¹³å°çš„ç™»å½•ä¼šè¯ID** |

### å•å¹³å°çˆ¬è™«è¯·æ±‚å‚æ•°

| å‚æ•°å | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|------|--------|------|
| platform | string | æ˜¯ | - | å¹³å°ï¼šxhs, dy, ks, bili, wb, tieba, zhihu |
| login_type | string | å¦ | qrcode | ç™»å½•ç±»å‹ï¼šqrcode, phone, cookie |
| crawler_type | string | å¦ | search | çˆ¬å–ç±»å‹ï¼šsearch, detail, creator |
| keywords | string | å¦ | "" | æœç´¢å…³é”®è¯ |
| start_page | int | å¦ | 1 | å¼€å§‹é¡µæ•° |
| get_comments | boolean | å¦ | true | æ˜¯å¦çˆ¬å–è¯„è®º |
| get_sub_comments | boolean | å¦ | false | æ˜¯å¦çˆ¬å–äºŒçº§è¯„è®º |
| save_data_option | string | å¦ | json | æ•°æ®ä¿å­˜æ–¹å¼ï¼šcsv, db, json |
| cookies | string | å¦ | "" | Cookieå­—ç¬¦ä¸² |
| specified_ids | array | å¦ | null | æŒ‡å®šIDåˆ—è¡¨ |
| max_notes_count | int | å¦ | 200 | æœ€å¤§çˆ¬å–æ•°é‡ |
| enable_images | boolean | å¦ | false | æ˜¯å¦æŠ“å–å›¾ç‰‡ |
| **use_proxy** | **boolean** | **å¦** | **false** | **æ˜¯å¦ä½¿ç”¨ä»£ç†** |
| **proxy_strategy** | **string** | **å¦** | **round_robin** | **ä»£ç†ç­–ç•¥ï¼šround_robin, random, weighted, failover, geo_based, smart** |

### ä»£ç†ç­–ç•¥è¯´æ˜

- **round_robin**: è½®è¯¢ç­–ç•¥ - æŒ‰é¡ºåºè½®è¯¢ä½¿ç”¨ä»£ç†
- **random**: éšæœºç­–ç•¥ - éšæœºé€‰æ‹©ä»£ç†
- **weighted**: æƒé‡ç­–ç•¥ - æ ¹æ®ä»£ç†æƒé‡é€‰æ‹©
- **failover**: æ•…éšœè½¬ç§»ç­–ç•¥ - ä¼˜å…ˆä½¿ç”¨é«˜å¯ç”¨ä»£ç†ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢
- **geo_based**: åœ°ç†ä½ç½®ç­–ç•¥ - æ ¹æ®ç›®æ ‡ç½‘ç«™åœ°ç†ä½ç½®é€‰æ‹©ä»£ç†
- **smart**: æ™ºèƒ½ç­–ç•¥ - ç»¼åˆé€Ÿåº¦ã€å¯ç”¨æ€§ç­‰å› ç´ æ™ºèƒ½é€‰æ‹©

## ä½¿ç”¨ç¤ºä¾‹

### Python å¤šå¹³å°æŠ“å–ç¤ºä¾‹

```python
import requests
import time

def start_multi_platform_crawl():
    """å¯åŠ¨å¤šå¹³å°æŠ“å–ä»»åŠ¡"""
    url = "http://localhost:8000/api/v1/multi-platform/start"
    payload = {
        "platforms": ["xhs", "dy", "ks"],
        "keywords": "ç¾é£Ÿæ¢åº—",
        "max_count_per_platform": 30,
        "enable_comments": False,
        "enable_images": True,
        "save_format": "json"
    }
    
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        result = response.json()
        task_id = result["task_id"]
        print(f"ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")
        return task_id
    else:
        print(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {response.text}")
        return None

def monitor_multi_platform_task(task_id):
    """ç›‘æ§å¤šå¹³å°ä»»åŠ¡çŠ¶æ€"""
    while True:
        response = requests.get(f"http://localhost:8000/api/v1/multi-platform/status/{task_id}")
        if response.status_code == 200:
            status = response.json()
            print(f"ä»»åŠ¡çŠ¶æ€: {status['status']}")
            print(f"è¿›åº¦: {status['progress']['completed']}/{status['progress']['total']}")
            
            if status['status'] in ['completed', 'failed']:
                return status
        
        time.sleep(5)

def get_multi_platform_results(task_id):
    """è·å–å¤šå¹³å°ä»»åŠ¡ç»“æœ"""
    response = requests.get(f"http://localhost:8000/api/v1/multi-platform/results/{task_id}?format_type=json")
    if response.status_code == 200:
        results = response.json()
        print(f"æ€»å…±è·å– {results['total_count']} æ¡æ•°æ®")
        
        # æŒ‰å¹³å°ç»Ÿè®¡
        platform_stats = {}
        for item in results['results']:
            platform = item['platform_name']
            platform_stats[platform] = platform_stats.get(platform, 0) + 1
        
        print("æŒ‰å¹³å°ç»Ÿè®¡:")
        for platform, count in platform_stats.items():
            print(f"  {platform}: {count} æ¡")
        
        return results
    else:
        print(f"è·å–ç»“æœå¤±è´¥: {response.text}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
task_id = start_multi_platform_crawl()
if task_id:
    status = monitor_multi_platform_task(task_id)
    if status['status'] == 'completed':
        results = get_multi_platform_results(task_id)
```

### Python å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆå¸¦ä»£ç†ï¼‰

```python
import requests
import time

# å¯åŠ¨å¸¦ä»£ç†çš„çˆ¬è™«ä»»åŠ¡
def start_crawler_with_proxy(platform="xhs", keywords="ç¼–ç¨‹"):
    url = "http://localhost:8000/api/v1/crawler/start"
    payload = {
        "platform": platform,
        "keywords": keywords,
        "max_notes_count": 10,
        "get_comments": False,
        "use_proxy": True,
        "proxy_strategy": "smart"
    }
    
    response = requests.post(url, json=payload)
    return response.json()

# è·å–ä»£ç†ç»Ÿè®¡
def get_proxy_stats():
    url = "http://localhost:8000/api/v1/proxy/stats"
    response = requests.get(url)
    return response.json()

# å¿«é€Ÿè·å–ä»£ç†
def get_proxy(strategy="smart", platform="xhs"):
    url = f"http://localhost:8000/api/v1/proxy/quick-get?strategy_type={strategy}&platform={platform}"
    response = requests.get(url)
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æŸ¥çœ‹ä»£ç†ç»Ÿè®¡
    stats = get_proxy_stats()
    print(f"ä»£ç†ç»Ÿè®¡: {stats}")
    
    # è·å–ä»£ç†
    proxy = get_proxy("smart", "xhs")
    print(f"è·å–ä»£ç†: {proxy}")
    
    # å¯åŠ¨çˆ¬è™«ä»»åŠ¡
    result = start_crawler_with_proxy("xhs", "Pythonç¼–ç¨‹")
    task_id = result["data"]["task_id"]
    print(f"ä»»åŠ¡ID: {task_id}")
```

### JavaScript å¤šå¹³å°æŠ“å–ç¤ºä¾‹

```javascript
// å¯åŠ¨å¤šå¹³å°æŠ“å–ä»»åŠ¡
async function startMultiPlatformCrawl() {
    const data = {
        platforms: ["xhs", "dy", "ks"],
        keywords: "ç¾é£Ÿæ¢åº—",
        max_count_per_platform: 30,
        enable_comments: false,
        enable_images: true,
        save_format: "json"
    };
    
    try {
        const response = await fetch('http://localhost:8000/api/v1/multi-platform/start', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(data)
        });
        
        const result = await response.json();
        
        if (response.ok) {
            console.log(`ä»»åŠ¡åˆ›å»ºæˆåŠŸ: ${result.task_id}`);
            return result.task_id;
        } else {
            console.error(`åˆ›å»ºä»»åŠ¡å¤±è´¥: ${result.detail}`);
            return null;
        }
    } catch (error) {
        console.error('è¯·æ±‚å¤±è´¥:', error);
        return null;
    }
}

// ç›‘æ§ä»»åŠ¡çŠ¶æ€
async function monitorTaskStatus(taskId) {
    while (true) {
        try {
            const response = await fetch(`http://localhost:8000/api/v1/multi-platform/status/${taskId}`);
            const status = await response.json();
            
            if (response.ok) {
                console.log(`ä»»åŠ¡çŠ¶æ€: ${status.status}`);
                console.log(`è¿›åº¦: ${status.progress.completed}/${status.progress.total}`);
                
                if (status.status === 'completed' || status.status === 'failed') {
                    return status;
                }
            } else {
                console.error(`è·å–çŠ¶æ€å¤±è´¥: ${status.detail}`);
                return null;
            }
        } catch (error) {
            console.error('è¯·æ±‚å¤±è´¥:', error);
            return null;
        }
        
        // ç­‰å¾…5ç§’
        await new Promise(resolve => setTimeout(resolve, 5000));
    }
}

// è·å–ä»»åŠ¡ç»“æœ
async function getTaskResults(taskId) {
    try {
        const response = await fetch(`http://localhost:8000/api/v1/multi-platform/results/${taskId}?format_type=json`);
        const results = await response.json();
        
        if (response.ok) {
            console.log(`æ€»å…±è·å– ${results.total_count} æ¡æ•°æ®`);
            
            // æŒ‰å¹³å°ç»Ÿè®¡
            const platformStats = {};
            results.results.forEach(item => {
                const platform = item.platform_name;
                platformStats[platform] = (platformStats[platform] || 0) + 1;
            });
            
            console.log('æŒ‰å¹³å°ç»Ÿè®¡:');
            Object.entries(platformStats).forEach(([platform, count]) => {
                console.log(`  ${platform}: ${count} æ¡`);
            });
            
            return results;
        } else {
            console.error(`è·å–ç»“æœå¤±è´¥: ${results.detail}`);
            return null;
        }
    } catch (error) {
        console.error('è¯·æ±‚å¤±è´¥:', error);
        return null;
    }
}

// ä¸»å‡½æ•°
async function main() {
    const taskId = await startMultiPlatformCrawl();
    if (!taskId) return;
    
    const status = await monitorTaskStatus(taskId);
    if (!status || status.status === 'failed') {
        console.log('ä»»åŠ¡æ‰§è¡Œå¤±è´¥');
        return;
    }
    
    const results = await getTaskResults(taskId);
    if (results) {
        console.log('ä»»åŠ¡å®Œæˆï¼');
    }
}

// è¿è¡Œ
main();
```

### cURL ç¤ºä¾‹

```bash
# å¤šå¹³å°æŠ“å–
curl -X POST "http://localhost:8000/api/v1/multi-platform/start" \
  -H "Content-Type: application/json" \
  -d '{
    "platforms": ["xhs", "dy", "ks"],
    "keywords": "ç¾é£Ÿæ¢åº—",
    "max_count_per_platform": 30,
    "enable_images": true,
    "save_format": "json"
  }'

# è·å–ä»»åŠ¡çŠ¶æ€
curl "http://localhost:8000/api/v1/multi-platform/status/{task_id}"

# è·å–ä»»åŠ¡ç»“æœ
curl "http://localhost:8000/api/v1/multi-platform/results/{task_id}?format_type=json"

# å•å¹³å°æŠ“å–ï¼ˆå¸¦ä»£ç†ï¼‰
curl -X POST "http://localhost:8000/api/v1/crawler/start" \
  -H "Content-Type: application/json" \
  -d '{
    "platform": "xhs",
    "keywords": "ç¼–ç¨‹",
    "max_notes_count": 10,
    "use_proxy": true,
    "proxy_strategy": "smart"
  }'
```

## é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯ç 

| çŠ¶æ€ç  | è¯´æ˜ | è§£å†³æ–¹æ¡ˆ |
|--------|------|----------|
| 400 | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼å’Œå¿…å¡«å­—æ®µ |
| 404 | ä»»åŠ¡ä¸å­˜åœ¨ | ç¡®è®¤ä»»åŠ¡IDæ˜¯å¦æ­£ç¡® |
| 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—ï¼Œè”ç³»ç®¡ç†å‘˜ |

### é”™è¯¯å“åº”ç¤ºä¾‹

```json
{
  "detail": "ä¸æ”¯æŒçš„å¹³å°: ['invalid_platform']"
}
```

## æœ€ä½³å®è·µ

### 1. å¤šå¹³å°æŠ“å–
- åˆç†é€‰æ‹©å¹³å°ç»„åˆï¼Œé¿å…è¿‡å¤šå¹³å°åŒæ—¶æŠ“å–
- è®¾ç½®åˆé€‚çš„æŠ“å–æ•°é‡ï¼Œé¿å…å¯¹å¹³å°é€ æˆå‹åŠ›
- ä½¿ç”¨ä»»åŠ¡çŠ¶æ€ç›‘æ§ï¼ŒåŠæ—¶å¤„ç†å¼‚å¸¸

### 2. ä»£ç†ä½¿ç”¨
- æ ¹æ®ç›®æ ‡å¹³å°é€‰æ‹©åˆé€‚çš„ä»£ç†ç­–ç•¥
- å®šæœŸæ£€æµ‹ä»£ç†å¯ç”¨æ€§
- åˆç†é…ç½®ä»£ç†æ± å¤§å°

### 3. é”™è¯¯å¤„ç†
- å®ç°é‡è¯•æœºåˆ¶
- è®°å½•é”™è¯¯æ—¥å¿—
- æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯

### 4. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨å¼‚æ­¥è¯·æ±‚
- å®ç°è¯·æ±‚ç¼“å­˜
- æ§åˆ¶å¹¶å‘æ•°é‡

## æ³¨æ„äº‹é¡¹

1. **åˆè§„ä½¿ç”¨**ï¼šè¯·éµå®ˆå„å¹³å°çš„ä½¿ç”¨æ¡æ¬¾
2. **é¢‘ç‡æ§åˆ¶**ï¼šé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
3. **æ•°æ®ç”¨é€”**ï¼šä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨
4. **å­˜å‚¨ç®¡ç†**ï¼šæ³¨æ„ç®¡ç†æŠ“å–æ•°æ®çš„å­˜å‚¨ç©ºé—´
5. **ç½‘ç»œç¯å¢ƒ**ï¼šç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š

## æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹APIå“åº”ä¸­çš„é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—
3. ç¡®è®¤è¯·æ±‚å‚æ•°æ ¼å¼
4. å‚è€ƒç¤ºä¾‹ä»£ç 
5. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½