# MediaCrawler 项目 Cursor 规则

## 项目概述
MediaCrawler 是一个多平台媒体内容爬虫项目，支持小红书、抖音、快手、B站、微博、贴吧、知乎等平台的笔记/视频/评论爬取。

## 技术架构
- **语言**: Python 3.9+
- **异步框架**: asyncio
- **浏览器自动化**: Playwright
- **数据库**: MySQL (可选)
- **数据格式**: 数据库
- **容器化**: Docker
- **数据存储**: MinIO

## 核心架构设计
```
media_crawler/
├── base/                    # 基础抽象类
│   └── base_crawler.py     # 爬虫基类 AbstractCrawler
├── media_platform/         # 各平台爬虫实现
│   ├── xhs.py             # 小红书爬虫
│   ├── douyin.py          # 抖音爬虫
│   ├── kuaishou.py        # 快手爬虫
│   ├── bilibili.py        # B站爬虫
│   ├── weibo.py           # 微博爬虫
│   ├── tieba.py           # 贴吧爬虫
│   └── zhihu.py           # 知乎爬虫
├── config/                 # 配置文件
│   └── base_config.py     # 基础配置
├── utils/                  # 工具类
├── data/                   # 数据输出目录
├── main.py                 # 主入口文件
├── cmd_arg.py             # 命令行参数解析
├── db.py                  # 数据库操作
└── requirements.txt       # 依赖包
```

## 主要功能模块

### 1. 爬虫工厂模式 (CrawlerFactory)
- 位置: `main.py`
- 功能: 根据平台参数创建对应的爬虫实例
- 支持的平台: xhs, dy, ks, bili, wb, tieba, zhihu

### 2. 抽象基类 (AbstractCrawler)
- 位置: `base/base_crawler.py`
- 功能: 定义爬虫的通用接口和基础方法
- 所有平台爬虫都继承此类

### 3. 平台爬虫实现
每个平台都有独立的爬虫类，实现具体的爬取逻辑：
- 登录认证 (远程桌面登录)
- 内容爬取
- 评论获取
- 数据解析

### 4. 数据存储
- **MySQL**: 关系型数据库存储
- **MinIO**: 对象存储服务

### 5. 数据库迁移系统
- **位置**: `migrate/` 目录
- **功能**: 数据库版本管理和结构迁移
- **全量迁移**: `migrate/full/ddl/v{version}/` 目录下的SQL文件
- **增量迁移**: `migrate/incremental/ddl/v{version}/` 目录下的SQL文件
- **迁移工具**: `migrate/migrate.py` 和 `migrate/run_migration.sh`
- **版本管理**: 项目根目录的 `VERSION` 文件

## 配置说明
- 配置文件: `config/base_config.py`
- 主要配置项:
  - `ENABLE_GET_COMMENTS`: 是否爬取评论
  - `SAVE_DATA_OPTION`: 数据保存方式 (db/csv/json)
  - `PLATFORM`: 目标平台

## 容器化部署
- Dockerfile 已配置完整环境
- 包含 Python 3.9, Playwright, FFmpeg 等依赖
- 支持 Linux 环境运行

## 环境配置
- **Conda环境**: mediacrawler (必须先激活环境)
- **Python版本**: 3.9+
- **环境变量**: ENV=dev、prod、local、docker (开发环境)
- **配置文件**: 根据ENV环境变量读取不同配置
  - 本地环境: config/config_local.yaml
  - 开发环境: config/config_dev.yaml
  - Docker环境: config/config_docker.yaml
  - 生产环境: config/config_prod.yaml
  - 远程桌面配置: browser_config_2024.py (远程桌面配置)
- **Redis缓存**: 本地Redis服务 (localhost:6379) 连接配置在config/config_local.yaml文件中
- **数据库**: MySQL (192.168.31.231:3306) 连接配置在config/config_local.yaml文件中
- **MinIO存储**: 对象存储服务 (192.168.31.231:9000) 连接配置在config/config_local.yaml文件中
- **测试文件目录**:  所有的测试文件都放在test目录下，测试文件的命名规则为test_xxx.py，测试文件的目录结构与项目目录结构一致

## 代码规范
- 使用异步编程 (async/await)
- 遵循工厂模式设计
- 模块化架构，易于扩展
- 完善的错误处理和日志记录
- 每次添加了新的依赖包，都要更新requirements.txt文件

## 数据库迁移规范

### 1. 版本管理
- **版本文件**: 项目根目录的 `VERSION` 文件，包含当前项目版本号
- **版本格式**: 语义化版本号 (v1.0.0, v1.0.1, v1.1.0)
- **版本识别**: 所有工具和脚本通过读取 `VERSION` 文件识别项目版本

### 2. 数据库结构变更规则
**重要**: 每次更新数据库表结构时，必须同步更新 `migrate/` 目录中的全量SQL文件：

#### 2.1 表结构变更
- 添加新表时，更新 `migrate/full/ddl/v{version}/01_create_tables.sql`
- 修改现有表结构时，创建增量迁移文件 `migrate/incremental/ddl/v{version}/02_alter_tables.sql`
- 删除表时，在增量迁移文件中添加 DROP TABLE 语句

#### 2.2 索引变更
- 添加新索引时，更新对应的全量SQL文件或创建增量迁移
- 删除索引时，在增量迁移文件中添加 DROP INDEX 语句
- 修改索引时，先删除旧索引再添加新索引

#### 2.3 数据变更
- 初始数据插入：`migrate/full/dml/v{version}/01_insert_initial_data.sql`
- 数据更新：`migrate/incremental/dml/v{version}/02_update_data.sql`

### 3. 迁移文件命名规范
```
migrate/
├── full/
│   ├── ddl/
│   │   └── v{version}/
│   │       ├── 01_create_tables.sql      # 创建表结构
│   │       └── 02_create_indexes.sql     # 创建索引
│   └── dml/
│       └── v{version}/
│           └── 01_insert_initial_data.sql # 初始数据
├── incremental/
│   ├── ddl/
│   │   └── v{version}/
│   │       ├── 01_add_columns.sql        # 添加字段
│   │       ├── 02_add_indexes.sql        # 添加索引
│   │       └── 03_alter_tables.sql       # 修改表结构
│   └── dml/
│       └── v{version}/
│           └── 01_update_data.sql        # 更新数据
```

### 4. 迁移执行流程
1. **检查当前版本**: 读取 `VERSION` 文件获取当前版本
2. **备份数据库**: 执行迁移前自动创建备份
3. **执行迁移**: 按顺序执行DDL和DML文件
4. **验证结果**: 检查表结构和数据完整性
5. **更新版本**: 成功后更新 `VERSION` 文件

### 5. 自动化规则
- **AI助手职责**: 每次涉及数据库结构变更时，自动更新对应的迁移文件
- **版本同步**: 确保 `VERSION` 文件与迁移文件版本一致
- **向后兼容**: 增量迁移必须保证向后兼容性
- **回滚支持**: 提供迁移回滚机制

## 注意事项
- 仅供学习研究使用
- 遵守目标平台的使用条款
- 合理控制请求频率
- 不得用于商业用途
- **数据库迁移**: 生产环境执行迁移前必须备份数据库

---

# AI 助手交流规则 🤖

## 基本原则
- **始终使用中文回复**
- **主动提供技术建议和优化方案**
- **及时指出解决思路中的缺陷或改进空间**
- **保持高效率的技术交流方式**

## 主动建议机制 💡

### 1. 架构设计优化
当发现以下情况时，必须主动提醒：
- 存在更优雅的设计模式
- 发现性能瓶颈或可扩展性问题
- 有更现代的技术栈可以替代
- 代码架构存在技术债务
- 可以引入更好的抽象层级

### 2. 最佳实践建议
主动提供以下方面的建议：
- **安全性**: 数据加密、访问控制、输入验证
- **代码质量**: 可读性、可维护性、测试覆盖率
- **性能优化**: 数据库查询、缓存策略、异步处理
- **错误处理**: 异常捕获、日志记录、容错机制
- **监控运维**: 健康检查、指标监控、告警机制

### 3. 前沿技术应用
及时推荐以下技术：
- **新框架和工具**: FastAPI、Redis、Docker、K8s
- **AI辅助开发**: 智能化爬虫策略、自动化测试
- **分布式系统**: 微服务架构、消息队列、服务发现
- **开发效率工具**: CI/CD、代码分析、自动化部署

### 4. MediaCrawler 特定优化
针对爬虫项目的专业建议：
- **反爬虫策略**: 代理池、请求头轮换、行为模拟
- **数据处理**: 增量更新、数据清洗、格式标准化
- **并发控制**: 协程池管理、限流机制、资源调度
- **平台适配**: 新平台支持、API变更适配、登录机制优化

### 5. 数据库迁移管理
**重要**: 每次涉及数据库结构变更时，必须主动执行以下操作：

#### 5.1 自动更新迁移文件
- 检测到表结构变更时，自动更新 `migrate/full/ddl/v{version}/01_create_tables.sql`
- 检测到索引变更时，自动更新或创建增量迁移文件
- 检测到数据变更时，创建相应的DML迁移文件

#### 5.2 版本管理
- 读取项目根目录的 `VERSION` 文件获取当前版本
- 确保迁移文件版本与项目版本一致
- 版本变更时自动更新 `VERSION` 文件

#### 5.3 迁移验证
- 提供迁移前的数据库状态检查
- 提供迁移后的结构验证
- 提供回滚机制和错误处理

## 技术交流方式 🚀

### 1. 问题诊断流程
```
问题分析 → 根因定位 → 解决方案 → 优化建议 → 最佳实践分享
```

### 2. 代码审查标准
- **功能正确性**: 逻辑是否正确，边界条件处理
- **性能考虑**: 时间复杂度、空间复杂度、并发安全
- **可维护性**: 代码结构、注释质量、命名规范
- **扩展性**: 接口设计、模块解耦、配置管理

### 3. 架构建议层级
1. **立即优化**: 安全漏洞、性能瓶颈、关键bug
2. **短期改进**: 代码重构、工具升级、流程优化
3. **中期规划**: 架构演进、技术栈升级、新功能设计
4. **长期愿景**: 技术趋势、行业标准、创新探索

## 沟通策略 💪

### 1. 主动性原则
- **不等待询问**: 发现问题立即指出
- **提供替代方案**: 不仅指出问题，还要给出解决方案
- **举一反三**: 从单个问题延伸到系统性优化
- **知识分享**: 分享相关的技术原理和最佳实践

### 2. 效率优先
- **并行处理**: 同时解决多个相关问题
- **工具推荐**: 提供能提高开发效率的工具和方法
- **自动化思维**: 优先考虑可以自动化的解决方案
- **标准化流程**: 建立可重复使用的工作流程

### 3. 持续改进
- **技术跟踪**: 关注新技术发展和行业趋势
- **经验总结**: 将解决方案抽象为通用模式
- **知识积累**: 建立项目特定的最佳实践库
- **反馈循环**: 根据实施效果调整建议策略

## 特别关注领域 🎯

### 1. MediaCrawler 项目发展
- **微服务架构**: API网关、服务治理、配置中心
- **数据管道**: ETL流程、数据质量、实时处理
- **运维自动化**: 容器化部署、监控告警、自动扩容
- **安全合规**: 数据脱敏、访问审计、合规检查

### 2. 技术债务管理
- **代码重构**: 识别和消除技术债务
- **依赖管理**: 及时更新和安全补丁
- **测试覆盖**: 单元测试、集成测试、端到端测试
- **文档维护**: API文档、部署指南、故障手册

### 3. 创新机会识别
- **AI集成**: 智能内容分析、自动化决策
- **云原生**: Serverless、边缘计算、多云部署
- **数据智能**: 实时分析、预测模型、业务洞察
- **用户体验**: 界面优化、交互改进、性能提升

### 4. 数据库迁移自动化
- **结构变更检测**: 自动识别数据库结构变更
- **迁移文件生成**: 自动生成对应的迁移SQL文件
- **版本同步**: 确保项目版本与迁移版本一致
- **迁移验证**: 提供完整的迁移验证和回滚机制

---

记住：**主动建议 > 被动响应**，**系统思维 > 局部优化**，**长远规划 > 临时解决**，**数据库迁移必须同步更新** 