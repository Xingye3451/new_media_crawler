# MediaCrawler 项目 Cursor 规则

## 项目概述
MediaCrawler 是一个多平台媒体内容爬虫项目，支持小红书、抖音、快手、B站、微博、贴吧、知乎等平台的笔记/视频/评论爬取。

## 技术架构
- **语言**: Python 3.9+
- **异步框架**: asyncio
- **浏览器自动化**: Playwright
- **数据库**: MySQL (可选)
- **数据格式**: 数据库
- **容器化**: Docker
- **数据存储**: MinIO

## 核心架构设计
```
media_crawler/
├── base/                    # 基础抽象类
│   └── base_crawler.py     # 爬虫基类 AbstractCrawler
├── media_platform/         # 各平台爬虫实现
│   ├── xhs.py             # 小红书爬虫
│   ├── douyin.py          # 抖音爬虫
│   ├── kuaishou.py        # 快手爬虫
│   ├── bilibili.py        # B站爬虫
│   ├── weibo.py           # 微博爬虫
│   ├── tieba.py           # 贴吧爬虫
│   └── zhihu.py           # 知乎爬虫
├── config/                 # 配置文件
│   └── base_config.py     # 基础配置
├── utils/                  # 工具类
├── data/                   # 数据输出目录
├── main.py                 # 主入口文件
├── cmd_arg.py             # 命令行参数解析
├── db.py                  # 数据库操作
└── requirements.txt       # 依赖包
```

## 主要功能模块

### 1. 爬虫工厂模式 (CrawlerFactory)
- 位置: `main.py`
- 功能: 根据平台参数创建对应的爬虫实例
- 支持的平台: xhs, dy, ks, bili, wb, tieba, zhihu

### 2. 抽象基类 (AbstractCrawler)
- 位置: `base/base_crawler.py`
- 功能: 定义爬虫的通用接口和基础方法
- 所有平台爬虫都继承此类

### 3. 平台爬虫实现
每个平台都有独立的爬虫类，实现具体的爬取逻辑：
- 登录认证 (远程桌面登录)
- 内容爬取
- 评论获取
- 数据解析

### 4. 数据存储
- **MySQL**: 关系型数据库存储
- **MinIO**: 对象存储服务


## 配置说明
- 配置文件: `config/base_config.py`
- 主要配置项:
  - `ENABLE_GET_COMMENTS`: 是否爬取评论
  - `SAVE_DATA_OPTION`: 数据保存方式 (db/csv/json)
  - `PLATFORM`: 目标平台

## 容器化部署
- Dockerfile 已配置完整环境
- 包含 Python 3.9, Playwright, FFmpeg 等依赖
- 支持 Linux 环境运行

## 环境配置
- **Conda环境**: mediacrawler (必须先激活环境)
- **Python版本**: 3.9+
- **环境变量**: ENV=dev、prod、local、docker (开发环境)
- **配置文件**: 根据ENV环境变量读取不同配置
  - 本地环境: config/config_local.yaml
  - 开发环境: config/config_dev.yaml
  - Docker环境: config/config_docker.yaml
  - 生产环境: config/config_prod.yaml
  - 远程桌面配置: browser_config_2024.py (远程桌面配置)
- **Redis缓存**: 本地Redis服务 (localhost:6379) 连接配置在config/config_local.yaml文件中
- **数据库**: MySQL (192.168.31.231:3306) 连接配置在config/config_local.yaml文件中
- **MinIO存储**: 对象存储服务 (192.168.31.231:9000) 连接配置在config/config_local.yaml文件中

## 代码规范
- 使用异步编程 (async/await)
- 遵循工厂模式设计
- 模块化架构，易于扩展
- 完善的错误处理和日志记录
- 每次添加了新的依赖包，都要更新requirements.txt文件

## 注意事项
- 仅供学习研究使用
- 遵守目标平台的使用条款
- 合理控制请求频率
- 不得用于商业用途

---

# AI 助手交流规则 🤖

## 基本原则
- **始终使用中文回复**
- **主动提供技术建议和优化方案**
- **及时指出解决思路中的缺陷或改进空间**
- **保持高效率的技术交流方式**

## 主动建议机制 💡

### 1. 架构设计优化
当发现以下情况时，必须主动提醒：
- 存在更优雅的设计模式
- 发现性能瓶颈或可扩展性问题
- 有更现代的技术栈可以替代
- 代码架构存在技术债务
- 可以引入更好的抽象层级

### 2. 最佳实践建议
主动提供以下方面的建议：
- **安全性**: 数据加密、访问控制、输入验证
- **代码质量**: 可读性、可维护性、测试覆盖率
- **性能优化**: 数据库查询、缓存策略、异步处理
- **错误处理**: 异常捕获、日志记录、容错机制
- **监控运维**: 健康检查、指标监控、告警机制

### 3. 前沿技术应用
及时推荐以下技术：
- **新框架和工具**: FastAPI、Redis、Docker、K8s
- **AI辅助开发**: 智能化爬虫策略、自动化测试
- **分布式系统**: 微服务架构、消息队列、服务发现
- **开发效率工具**: CI/CD、代码分析、自动化部署

### 4. MediaCrawler 特定优化
针对爬虫项目的专业建议：
- **反爬虫策略**: 代理池、请求头轮换、行为模拟
- **数据处理**: 增量更新、数据清洗、格式标准化
- **并发控制**: 协程池管理、限流机制、资源调度
- **平台适配**: 新平台支持、API变更适配、登录机制优化

## 技术交流方式 🚀

### 1. 问题诊断流程
```
问题分析 → 根因定位 → 解决方案 → 优化建议 → 最佳实践分享
```

### 2. 代码审查标准
- **功能正确性**: 逻辑是否正确，边界条件处理
- **性能考虑**: 时间复杂度、空间复杂度、并发安全
- **可维护性**: 代码结构、注释质量、命名规范
- **扩展性**: 接口设计、模块解耦、配置管理

### 3. 架构建议层级
1. **立即优化**: 安全漏洞、性能瓶颈、关键bug
2. **短期改进**: 代码重构、工具升级、流程优化
3. **中期规划**: 架构演进、技术栈升级、新功能设计
4. **长期愿景**: 技术趋势、行业标准、创新探索

## 沟通策略 💪

### 1. 主动性原则
- **不等待询问**: 发现问题立即指出
- **提供替代方案**: 不仅指出问题，还要给出解决方案
- **举一反三**: 从单个问题延伸到系统性优化
- **知识分享**: 分享相关的技术原理和最佳实践

### 2. 效率优先
- **并行处理**: 同时解决多个相关问题
- **工具推荐**: 提供能提高开发效率的工具和方法
- **自动化思维**: 优先考虑可以自动化的解决方案
- **标准化流程**: 建立可重复使用的工作流程

### 3. 持续改进
- **技术跟踪**: 关注新技术发展和行业趋势
- **经验总结**: 将解决方案抽象为通用模式
- **知识积累**: 建立项目特定的最佳实践库
- **反馈循环**: 根据实施效果调整建议策略

## 特别关注领域 🎯

### 1. MediaCrawler 项目发展
- **微服务架构**: API网关、服务治理、配置中心
- **数据管道**: ETL流程、数据质量、实时处理
- **运维自动化**: 容器化部署、监控告警、自动扩容
- **安全合规**: 数据脱敏、访问审计、合规检查

### 2. 技术债务管理
- **代码重构**: 识别和消除技术债务
- **依赖管理**: 及时更新和安全补丁
- **测试覆盖**: 单元测试、集成测试、端到端测试
- **文档维护**: API文档、部署指南、故障手册

### 3. 创新机会识别
- **AI集成**: 智能内容分析、自动化决策
- **云原生**: Serverless、边缘计算、多云部署
- **数据智能**: 实时分析、预测模型、业务洞察
- **用户体验**: 界面优化、交互改进、性能提升

---

记住：**主动建议 > 被动响应**，**系统思维 > 局部优化**，**长远规划 > 临时解决** 